{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5f644a0bfadb4dadb12cc9d92c686dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c878875eab6a472592f88ae09202f246",
              "IPY_MODEL_6e854dda3d094b24a496148b39700072",
              "IPY_MODEL_23232cbca4844e8880ab490e43d6e411"
            ],
            "layout": "IPY_MODEL_3f24f754029645b68b00663c269044e3"
          }
        },
        "c878875eab6a472592f88ae09202f246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42fd83ef56564700b2c3f937ccbdcd96",
            "placeholder": "​",
            "style": "IPY_MODEL_3c021f18ff144a4eab904f5125dab5d6",
            "value": "model.safetensors: 100%"
          }
        },
        "6e854dda3d094b24a496148b39700072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ebc00960ccc416c8ad56f667f94f7be",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4bc32fb3a6664c8794f5fc553e81b3c9",
            "value": 440449768
          }
        },
        "23232cbca4844e8880ab490e43d6e411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55da702ffd8e4e648d8db6b149d489ff",
            "placeholder": "​",
            "style": "IPY_MODEL_89f1d6297dcb41cab80c555a02ee6a65",
            "value": " 440M/440M [00:03&lt;00:00, 221MB/s]"
          }
        },
        "3f24f754029645b68b00663c269044e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42fd83ef56564700b2c3f937ccbdcd96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c021f18ff144a4eab904f5125dab5d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ebc00960ccc416c8ad56f667f94f7be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bc32fb3a6664c8794f5fc553e81b3c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55da702ffd8e4e648d8db6b149d489ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89f1d6297dcb41cab80c555a02ee6a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537,
          "referenced_widgets": [
            "5f644a0bfadb4dadb12cc9d92c686dc8",
            "c878875eab6a472592f88ae09202f246",
            "6e854dda3d094b24a496148b39700072",
            "23232cbca4844e8880ab490e43d6e411",
            "3f24f754029645b68b00663c269044e3",
            "42fd83ef56564700b2c3f937ccbdcd96",
            "3c021f18ff144a4eab904f5125dab5d6",
            "3ebc00960ccc416c8ad56f667f94f7be",
            "4bc32fb3a6664c8794f5fc553e81b3c9",
            "55da702ffd8e4e648d8db6b149d489ff",
            "89f1d6297dcb41cab80c555a02ee6a65"
          ]
        },
        "id": "gImZA4g3vBGn",
        "outputId": "599a7571-4ef0-49ce-adb4-1efad8211598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using device: cuda\n",
            "Labels: ['no_relation', 'brand', 'business division', 'business_division', 'chairperson', 'chief executive officer', 'chief_executive_officer', 'creator', 'currency', 'developer', 'director/manager', 'director_/_manager', 'distributed by', 'distributed_by', 'distribution format', 'distribution_format', 'employer', 'founded by', 'founded_by', 'headquarters location', 'headquarters_location', 'industry', 'legal form', 'legal_form', 'location of formation', 'location_of_formation', 'manufacturer', 'member of', 'member_of', 'operator', 'original broadcaster', 'original_broadcaster', 'owned by', 'owned_by', 'owner of', 'owner_of', 'parent organization', 'parent_organization', 'platform', 'position held', 'position_held', 'product/material produced', 'product_or_material_produced', 'publisher', 'stock exchange', 'stock_exchange', 'subsidiary']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer vocab size: 30526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded records: 5700 1007 1068\n",
            "Pair examples: 16570 3758 2672\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f644a0bfadb4dadb12cc9d92c686dc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "Training Epoch 1: 100%|██████████| 2072/2072 [12:51<00:00,  2.69it/s, loss=2.01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to: /content/drive/MyDrive/Datasets_EE782_course_project/FinRED_dataset/bert_pair_class_model_final\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 470/470 [00:57<00:00,  8.15it/s]\n",
            "Evaluating: 100%|██████████| 334/334 [00:39<00:00,  8.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DEV micro: (0.6508781266631187, 0.6508781266631187, 0.6508781266631187)\n",
            "DEV macro: (0.03836528221512247, 0.033478435800594425, 0.026596309975073975)\n",
            "\n",
            "TEST micro: (0.5239520958083832, 0.5239520958083832, 0.5239520958083832)\n",
            "TEST macro: (0.03229540584912485, 0.033984330774630346, 0.024406853804291414)\n",
            "Predictions saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "#              BERT-BASE + TPLinker-style Pair Classifier\n",
        "#                     (FINRED prepared JSON)\n",
        "# ================================================================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import os\n",
        "\n",
        "# -------------------- USER PATHS --------------------\n",
        "BASE_DRIVE = Path(\"/content/drive/MyDrive/Datasets_EE782_course_project/FinRED_dataset\")\n",
        "\n",
        "TRAIN_JSON = BASE_DRIVE / \"finred_tplinkertrain.json\"   # already converted JSON prepared earlier\n",
        "DEV_TXT   = BASE_DRIVE / \"finred_dev.txt\"\n",
        "TEST_TXT  = BASE_DRIVE / \"finred_test.txt\"\n",
        "RELATIONS_LIST = BASE_DRIVE / \"finred_relations.txt\"\n",
        "\n",
        "OUTPUT_DIR = BASE_DRIVE / \"bert_pair_class_model_final\"\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "# -------------------- RELATION LABELS --------------------\n",
        "def load_relation_set(train_json_path, relations_file=None):\n",
        "    rels = set()\n",
        "    if relations_file and relations_file.exists():\n",
        "        with open(relations_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            for ln in f:\n",
        "                r = ln.strip()\n",
        "                if r:\n",
        "                    rels.add(r)\n",
        "\n",
        "    if train_json_path.exists():\n",
        "        with open(train_json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "            for rec in data:\n",
        "                for rel in rec.get(\"relations\", []):\n",
        "                    rels.add(rel[\"type\"])\n",
        "\n",
        "    rels = sorted(list(rels))\n",
        "    if \"no_relation\" not in rels:\n",
        "        rels = [\"no_relation\"] + rels\n",
        "    return rels\n",
        "\n",
        "label_list = load_relation_set(TRAIN_JSON, RELATIONS_LIST)\n",
        "label2id = {l:i for i,l in enumerate(label_list)}\n",
        "id2label = {i:l for l,i in label2id.items()}\n",
        "print(\"Labels:\", label_list)\n",
        "\n",
        "# -------------------- TOKENIZER --------------------\n",
        "MODEL_NAME = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
        "\n",
        "special_tokens = [\"[E1]\",\"[/E1]\",\"[E2]\",\"[/E2]\"]\n",
        "tokenizer.add_tokens([t for t in special_tokens if t not in tokenizer.get_vocab()])\n",
        "print(\"Tokenizer vocab size:\", len(tokenizer))\n",
        "\n",
        "# -------------------- FINRED TXT PARSING --------------------\n",
        "def parse_finred_txt_line(line):\n",
        "    parts = [p.strip() for p in line.strip().split(\"|\")]\n",
        "    text = parts[0]\n",
        "    triples = []\n",
        "    for p in parts[1:]:\n",
        "        if not p: continue\n",
        "        a = [x.strip() for x in p.split(\";\") if x.strip()!=\"\"]\n",
        "        if len(a)!=3: continue\n",
        "        h,t,r = a\n",
        "        triples.append((h,t,r))\n",
        "    return {\"text\": text, \"triples\": triples}\n",
        "\n",
        "def load_finred_txt_as_converted(txt_path):\n",
        "    recs=[]\n",
        "    with open(txt_path,\"r\",encoding=\"utf-8\") as f:\n",
        "        for ln in f:\n",
        "            if not ln.strip(): continue\n",
        "            p = parse_finred_txt_line(ln)\n",
        "            text = p[\"text\"]\n",
        "            enc = tokenizer(text, return_offsets_mapping=True, add_special_tokens=False)\n",
        "            offsets = enc[\"offset_mapping\"]\n",
        "            tokens = tokenizer.convert_ids_to_tokens(enc[\"input_ids\"])\n",
        "\n",
        "            entities_dict={}\n",
        "            rels=[]\n",
        "            for (h,t,r) in p[\"triples\"]:\n",
        "                # find subject\n",
        "                pos=text.lower().find(h.lower())\n",
        "                if pos!=-1:\n",
        "                    start,pos_end = pos, pos+len(h)\n",
        "                    hs,he=None,None\n",
        "                    for i,(a,b) in enumerate(offsets):\n",
        "                        if a<=start<b: hs=i\n",
        "                        if a<pos_end<=b: he=i\n",
        "                    if hs is not None and he is not None:\n",
        "                        entities_dict[h]={\"start\":hs,\"end\":he}\n",
        "                # find object\n",
        "                pos=text.lower().find(t.lower())\n",
        "                if pos!=-1:\n",
        "                    start,pos_end=pos, pos+len(t)\n",
        "                    ts,te=None,None\n",
        "                    for i,(a,b) in enumerate(offsets):\n",
        "                        if a<=start<b: ts=i\n",
        "                        if a<pos_end<=b: te=i\n",
        "                    if ts is not None and te is not None:\n",
        "                        entities_dict[t]={\"start\":ts,\"end\":te}\n",
        "\n",
        "                if h in entities_dict and t in entities_dict:\n",
        "                    rels.append({\"type\":r,\n",
        "                                 \"head\":[entities_dict[h][\"start\"],entities_dict[h][\"end\"]],\n",
        "                                 \"tail\":[entities_dict[t][\"start\"],entities_dict[t][\"end\"]]})\n",
        "\n",
        "            recs.append({\n",
        "                \"text\": text,\n",
        "                \"tokens\": tokens,\n",
        "                \"entities\": [{\"start\":v[\"start\"],\"end\":v[\"end\"]} for v in entities_dict.values()],\n",
        "                \"relations\": rels\n",
        "            })\n",
        "    return recs\n",
        "\n",
        "# -------------------- LOAD DATA --------------------\n",
        "def load_train_json(json_path):\n",
        "    with open(json_path,\"r\",encoding=\"utf-8\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "train_records = load_train_json(TRAIN_JSON)\n",
        "dev_records   = load_finred_txt_as_converted(DEV_TXT)\n",
        "test_records  = load_finred_txt_as_converted(TEST_TXT)\n",
        "\n",
        "print(\"Loaded records:\", len(train_records), len(dev_records), len(test_records))\n",
        "\n",
        "# -------------------- BUILD ENTITY PAIRS --------------------\n",
        "def build_pair_examples(records):\n",
        "    examples=[]\n",
        "    for rec in records:\n",
        "        text=rec[\"text\"]\n",
        "        entities=rec[\"entities\"]\n",
        "        rels=rec.get(\"relations\",[])\n",
        "        rel_lookup={}\n",
        "        for r in rels:\n",
        "            rel_lookup[(tuple(r[\"head\"]),tuple(r[\"tail\"]))]=r[\"type\"]\n",
        "        enc = tokenizer(text, return_offsets_mapping=True, add_special_tokens=False)\n",
        "        offsets = enc[\"offset_mapping\"]\n",
        "\n",
        "        entity_items=[]\n",
        "        for e in entities:\n",
        "            s = e[\"start\"]\n",
        "            e_tok = e[\"end\"]\n",
        "\n",
        "            # --- SAFETY CHECKS ---\n",
        "            if s < 0 or e_tok < 0:\n",
        "              continue\n",
        "            if s >= len(offsets) or e_tok >= len(offsets):\n",
        "              continue\n",
        "            if s > e_tok:\n",
        "              continue\n",
        "\n",
        "            # compute char boundaries\n",
        "            cs = offsets[s][0]\n",
        "            ce = offsets[e_tok][1]\n",
        "\n",
        "            # if invalid offset range, skip entity\n",
        "            if cs is None or ce is None:\n",
        "              continue\n",
        "            if cs >= ce:\n",
        "              continue\n",
        "\n",
        "            ent_text = text[cs:ce]\n",
        "\n",
        "            entity_items.append({\n",
        "              \"start\": s,\n",
        "              \"end\": e_tok,\n",
        "              \"text\": ent_text\n",
        "            })\n",
        "\n",
        "\n",
        "        for i,h in enumerate(entity_items):\n",
        "            for j,t in enumerate(entity_items):\n",
        "                if i==j: continue\n",
        "                lbl=rel_lookup.get(( (h[\"start\"],h[\"end\"]), (t[\"start\"],t[\"end\"]) ), \"no_relation\")\n",
        "                examples.append({\n",
        "                    \"text\":text,\n",
        "                    \"head\":h,\n",
        "                    \"tail\":t,\n",
        "                    \"label\":lbl\n",
        "                })\n",
        "    return examples\n",
        "\n",
        "train_examples = build_pair_examples(train_records)\n",
        "dev_examples   = build_pair_examples(dev_records)\n",
        "test_examples  = build_pair_examples(test_records)\n",
        "\n",
        "print(\"Pair examples:\", len(train_examples), len(dev_examples), len(test_examples))\n",
        "\n",
        "# -------------------- DATASET --------------------\n",
        "class PairRelDataset(Dataset):\n",
        "    def __init__(self, examples, tokenizer, label2id, max_len=256):\n",
        "        self.examples=examples\n",
        "        self.tokenizer=tokenizer\n",
        "        self.label2id=label2id\n",
        "        self.max_len=max_len\n",
        "\n",
        "    def __len__(self): return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ex=self.examples[idx]\n",
        "        text=ex[\"text\"]\n",
        "\n",
        "        enc = self.tokenizer(text, return_offsets_mapping=True, add_special_tokens=False)\n",
        "        token_list = self.tokenizer.convert_ids_to_tokens(enc[\"input_ids\"])\n",
        "        offsets = enc[\"offset_mapping\"]\n",
        "\n",
        "        hs,he = ex[\"head\"][\"start\"], ex[\"head\"][\"end\"]\n",
        "        ts,te = ex[\"tail\"][\"start\"], ex[\"tail\"][\"end\"]\n",
        "\n",
        "        inserts=[\n",
        "            (he+1,\"[/E1]\"), (hs,\"[E1]\"),\n",
        "            (te+1,\"[/E2]\"), (ts,\"[E2]\")\n",
        "        ]\n",
        "        inserts = sorted(inserts, key=lambda x: x[0], reverse=True)\n",
        "        for pos,tok in inserts:\n",
        "            pos = min(max(pos,0), len(token_list))\n",
        "            token_list.insert(pos, tok)\n",
        "\n",
        "        input_ids = [self.tokenizer.cls_token_id] + self.tokenizer.convert_tokens_to_ids(token_list) + [self.tokenizer.sep_token_id]\n",
        "        if len(input_ids)>self.max_len:\n",
        "            input_ids = input_ids[:self.max_len-1] + [self.tokenizer.sep_token_id]\n",
        "\n",
        "        attention_mask=[1]*len(input_ids)\n",
        "        pad_len=self.max_len-len(input_ids)\n",
        "        if pad_len>0:\n",
        "            input_ids += [self.tokenizer.pad_token_id]*pad_len\n",
        "            attention_mask += [0]*pad_len\n",
        "\n",
        "        label_id=self.label2id.get(ex[\"label\"],self.label2id[\"no_relation\"])\n",
        "\n",
        "        return {\n",
        "            \"input_ids\":torch.tensor(input_ids),\n",
        "            \"attention_mask\":torch.tensor(attention_mask),\n",
        "            \"label\":torch.tensor(label_id)\n",
        "        }\n",
        "\n",
        "# -------------------- DATA LOADERS --------------------\n",
        "BATCH_SIZE=8\n",
        "train_ds=PairRelDataset(train_examples, tokenizer, label2id)\n",
        "dev_ds  =PairRelDataset(dev_examples, tokenizer, label2id)\n",
        "test_ds =PairRelDataset(test_examples, tokenizer, label2id)\n",
        "\n",
        "train_loader=DataLoader(train_ds,batch_size=BATCH_SIZE,shuffle=True)\n",
        "dev_loader  =DataLoader(dev_ds, batch_size=BATCH_SIZE)\n",
        "test_loader =DataLoader(test_ds,batch_size=BATCH_SIZE)\n",
        "\n",
        "# -------------------- MODEL --------------------\n",
        "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(label_list))\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.to(DEVICE)\n",
        "\n",
        "# standard settings (no thresholding)\n",
        "EPOCHS = 1\n",
        "LR = 2e-5\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=LR, weight_decay=0.01)\n",
        "total_steps=len(train_loader)*EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(0.1*total_steps), num_training_steps=total_steps)\n",
        "\n",
        "# -------------------- TRAIN --------------------\n",
        "model.train()\n",
        "for epoch in range(EPOCHS):\n",
        "    loop = tqdm.tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\")\n",
        "    for batch in loop:\n",
        "        ids=batch[\"input_ids\"].to(DEVICE)\n",
        "        att=batch[\"attention_mask\"].to(DEVICE)\n",
        "        labels=batch[\"label\"].to(DEVICE)\n",
        "\n",
        "        out=model(input_ids=ids, attention_mask=att, labels=labels)\n",
        "        loss=out.loss\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(),1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loop.set_postfix({\"loss\":loss.item()})\n",
        "\n",
        "# -------------------- SAVE --------------------\n",
        "model.save_pretrained(str(OUTPUT_DIR))\n",
        "tokenizer.save_pretrained(str(OUTPUT_DIR))\n",
        "print(\"Saved to:\", OUTPUT_DIR)\n",
        "\n",
        "# -------------------- EVALUATION --------------------\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    preds=[]; golds=[]\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm.tqdm(loader, desc=\"Evaluating\"):\n",
        "            ids=batch[\"input_ids\"].to(device)\n",
        "            att=batch[\"attention_mask\"].to(device)\n",
        "            labels=batch[\"label\"].to(device)\n",
        "\n",
        "            logits=model(input_ids=ids, attention_mask=att).logits\n",
        "            p=torch.argmax(logits,dim=-1).cpu().numpy()\n",
        "            g=labels.cpu().numpy()\n",
        "\n",
        "            preds.extend(p.tolist())\n",
        "            golds.extend(g.tolist())\n",
        "\n",
        "    p_micro,r_micro,f_micro,_=precision_recall_fscore_support(golds,preds,average='micro',zero_division=0)\n",
        "    p_macro,r_macro,f_macro,_=precision_recall_fscore_support(golds,preds,average='macro',zero_division=0)\n",
        "\n",
        "    return {\n",
        "        \"micro\":(p_micro,r_micro,f_micro),\n",
        "        \"macro\":(p_macro,r_macro,f_macro)\n",
        "    }, preds, golds\n",
        "\n",
        "dev_metrics, dev_preds, dev_golds = evaluate(model, dev_loader, DEVICE)\n",
        "test_metrics, test_preds, test_golds = evaluate(model, test_loader, DEVICE)\n",
        "\n",
        "print(\"\\nDEV micro:\",dev_metrics[\"micro\"])\n",
        "print(\"DEV macro:\",dev_metrics[\"macro\"])\n",
        "print(\"\\nTEST micro:\",test_metrics[\"micro\"])\n",
        "print(\"TEST macro:\",test_metrics[\"macro\"])\n",
        "\n",
        "# -------------------- SAVE PREDICTIONS --------------------\n",
        "pred_out={\n",
        "    \"dev\":[{\"pred\":id2label[p],\"gold\":id2label[g]} for p,g in zip(dev_preds,dev_golds)],\n",
        "    \"test\":[{\"pred\":id2label[p],\"gold\":id2label[g]} for p,g in zip(test_preds,test_golds)]\n",
        "}\n",
        "with open(OUTPUT_DIR/\"predictions_summary.json\",\"w\") as f:\n",
        "    json.dump(pred_out,f,indent=2)\n",
        "\n",
        "print(\"Predictions saved.\")\n"
      ]
    }
  ]
}