{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AteC4C-v7M6m",
        "outputId": "26bd935c-f8a4-4ea3-ddd3-2320df9c4f1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Saved transformed dataset to: /content/drive/MyDrive/Datasets_EE782_course_project/FinRED_dataset/finred_tplinkertrain.json\n",
            "\n",
            "Sample transformed entry:\n",
            "\n",
            "{\n",
            "    \"text\": \"NEW YORK (Reuters) - Apple Inc Chief Executive Steve Jobs sought to soothe investor concerns about his health on Monday, saying his weight loss was caused by a hormone imbalance that is relatively simple to treat.\",\n",
            "    \"tokens\": [\n",
            "        \"[CLS]\",\n",
            "        \"new\",\n",
            "        \"york\",\n",
            "        \"(\",\n",
            "        \"reuters\",\n",
            "        \")\",\n",
            "        \"-\",\n",
            "        \"apple\",\n",
            "        \"inc\",\n",
            "        \"chief\",\n",
            "        \"executive\",\n",
            "        \"steve\",\n",
            "        \"jobs\",\n",
            "        \"sought\",\n",
            "        \"to\",\n",
            "        \"so\",\n",
            "        \"##oth\",\n",
            "        \"##e\",\n",
            "        \"investor\",\n",
            "        \"concerns\",\n",
            "        \"about\",\n",
            "        \"his\",\n",
            "        \"health\",\n",
            "        \"on\",\n",
            "        \"monday\",\n",
            "        \",\",\n",
            "        \"saying\",\n",
            "        \"his\",\n",
            "        \"weight\",\n",
            "        \"loss\",\n",
            "        \"was\",\n",
            "        \"caused\",\n",
            "        \"by\",\n",
            "        \"a\",\n",
            "        \"hormone\",\n",
            "        \"imbalance\",\n",
            "        \"that\",\n",
            "        \"is\",\n",
            "        \"relatively\",\n",
            "        \"simple\",\n",
            "        \"to\",\n",
            "        \"treat\",\n",
            "        \".\",\n",
            "        \"[SEP]\"\n",
            "    ],\n",
            "    \"entities\": [\n",
            "        {\n",
            "            \"type\": \"ENTITY\",\n",
            "            \"start\": 7,\n",
            "            \"end\": 8\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"ENTITY\",\n",
            "            \"start\": 11,\n",
            "            \"end\": 12\n",
            "        }\n",
            "    ],\n",
            "    \"relations\": [\n",
            "        {\n",
            "            \"type\": \"founded_by\",\n",
            "            \"head\": [\n",
            "                7,\n",
            "                8\n",
            "            ],\n",
            "            \"tail\": [\n",
            "                11,\n",
            "                12\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"chief_executive_officer\",\n",
            "            \"head\": [\n",
            "                7,\n",
            "                8\n",
            "            ],\n",
            "            \"tail\": [\n",
            "                11,\n",
            "                12\n",
            "            ]\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------------------------------------\n",
        "# 1. Mount Google Drive\n",
        "# ---------------------------------------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from pathlib import Path\n",
        "import json\n",
        "from transformers import BertTokenizerFast\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"yiyanghkust/finbert-pretrain\")\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2. Helper: Convert character span → token span\n",
        "# ---------------------------------------------------------\n",
        "def char_to_token_span(text, entity, tokens, offsets):\n",
        "    \"\"\"Find token-level span for an entity using offsets.\"\"\"\n",
        "    start_char = text.lower().find(entity.lower())\n",
        "    if start_char == -1:\n",
        "        return None\n",
        "\n",
        "    end_char = start_char + len(entity)\n",
        "\n",
        "    token_start = token_end = None\n",
        "    for i, (s, e) in enumerate(offsets):\n",
        "        if s <= start_char < e:\n",
        "            token_start = i\n",
        "        if s < end_char <= e:\n",
        "            token_end = i\n",
        "\n",
        "    if token_start is not None and token_end is not None:\n",
        "        return [token_start, token_end]\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3. Conversion: FinRED → TPLinker JSON\n",
        "# ---------------------------------------------------------\n",
        "def convert_finred_to_tplinker(text, triples):\n",
        "    encoding = tokenizer(text, return_offsets_mapping=True)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"])\n",
        "    offsets = encoding[\"offset_mapping\"]\n",
        "\n",
        "    entity_spans = {}\n",
        "    relations_formatted = []\n",
        "\n",
        "    for head, tail, rel in triples:\n",
        "\n",
        "        # Head span\n",
        "        if head not in entity_spans:\n",
        "            head_span = char_to_token_span(text, head, tokens, offsets)\n",
        "            if head_span:\n",
        "                entity_spans[head] = {\"type\": \"ENTITY\", \"start\": head_span[0], \"end\": head_span[1]}\n",
        "\n",
        "        # Tail span\n",
        "        if tail not in entity_spans:\n",
        "            tail_span = char_to_token_span(text, tail, tokens, offsets)\n",
        "            if tail_span:\n",
        "                entity_spans[tail] = {\"type\": \"ENTITY\", \"start\": tail_span[0], \"end\": tail_span[1]}\n",
        "\n",
        "        # Relation record\n",
        "        if head in entity_spans and tail in entity_spans:\n",
        "            relations_formatted.append({\n",
        "                \"type\": rel,\n",
        "                \"head\": [entity_spans[head][\"start\"], entity_spans[head][\"end\"]],\n",
        "                \"tail\": [entity_spans[tail][\"start\"], entity_spans[tail][\"end\"]]\n",
        "            })\n",
        "\n",
        "    return {\n",
        "        \"text\": text,\n",
        "        \"tokens\": tokens,\n",
        "        \"entities\": list(entity_spans.values()),\n",
        "        \"relations\": relations_formatted\n",
        "    }\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4. Load FinRED-like file from Google Drive & Convert\n",
        "# ---------------------------------------------------------\n",
        "base = Path(\"/content/drive/MyDrive/Datasets_EE782_course_project/FinRED_dataset\")\n",
        "\n",
        "input_file = base / \"finred_train.txt\"    # <-- CHANGE TO YOUR PATH\n",
        "output_file = \"/content/drive/MyDrive/Datasets_EE782_course_project/FinRED_dataset/finred_tplinkertrain.json\"  # <-- OUTPUT PATH\n",
        "\n",
        "\n",
        "converted_data = []\n",
        "\n",
        "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "for line in lines:\n",
        "    parts = line.strip().split(\"|\")\n",
        "    text = parts[0].strip()\n",
        "\n",
        "    triples = []\n",
        "    for p in parts[1:]:\n",
        "        parts_split = [x.strip() for x in p.split(\";\") if x.strip() != \"\"]\n",
        "\n",
        "        if len(parts_split) != 3:\n",
        "            # print(\"Skipping invalid triple:\", p)  # enable this for debugging\n",
        "            continue\n",
        "\n",
        "        h, t, r = parts_split\n",
        "        triples.append((h, t, r))\n",
        "\n",
        "    converted_data.append(convert_finred_to_tplinker(text, triples))\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 5. Save transformed dataset back to Drive\n",
        "# ---------------------------------------------------------\n",
        "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(converted_data, f, indent=4)\n",
        "\n",
        "print(\"\\nSaved transformed dataset to:\", output_file)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 6. Print a sample transformed record\n",
        "# ---------------------------------------------------------\n",
        "print(\"\\nSample transformed entry:\\n\")\n",
        "print(json.dumps(converted_data[0], indent=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- FULL TRAIN/VAL/EVAL SCRIPT (Colab-ready) -----\n",
        "# Mount Drive (if not already mounted)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# Imports\n",
        "import json\n",
        "from pathlib import Path\n",
        "from collections import defaultdict, Counter\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import numpy as np\n",
        "import os\n",
        "import tqdm\n",
        "\n",
        "# -------------------- USER PATHS (update if needed) --------------------\n",
        "BASE_DRIVE = Path(\"/content/drive/MyDrive/Datasets_EE782_course_project/FinRED_dataset\")\n",
        "TRAIN_JSON = BASE_DRIVE / \"finred_tplinkertrain.json\"   # your converted train JSON\n",
        "DEV_TXT   = BASE_DRIVE / \"finred_dev.txt\"               # finred-style dev file (raw)\n",
        "TEST_TXT  = BASE_DRIVE / \"finred_test.txt\"              # finred-style test file (raw)\n",
        "RELATIONS_LIST = BASE_DRIVE / \"finred_relations.txt\"    # optional file with relation names (one per line)\n",
        "OUTPUT_DIR = BASE_DRIVE / \"finbert_pair_class_model_final\"\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "# -------------------- Utility: load relations list or infer --------------------\n",
        "def load_relation_set(train_json_path, relations_file=None):\n",
        "    rels = set()\n",
        "    # If relations file exists, load\n",
        "    if relations_file and relations_file.exists():\n",
        "        with open(relations_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            for ln in f:\n",
        "                r = ln.strip()\n",
        "                if r:\n",
        "                    rels.add(r)\n",
        "    # Also infer from train json\n",
        "    if train_json_path.exists():\n",
        "        with open(train_json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "            for rec in data:\n",
        "                for rel in rec.get(\"relations\", []):\n",
        "                    rels.add(rel[\"type\"])\n",
        "    # Ensure deterministic ordering, add 'no_relation'\n",
        "    rels = sorted(rels)\n",
        "    if \"no_relation\" not in rels:\n",
        "        rels = [\"no_relation\"] + rels\n",
        "    return rels\n",
        "\n",
        "label_list = load_relation_set(TRAIN_JSON, RELATIONS_LIST)\n",
        "label2id = {l:i for i,l in enumerate(label_list)}\n",
        "id2label = {i:l for l,i in label2id.items()}\n",
        "print(\"Labels:\", label_list)\n",
        "\n",
        "# -------------------- Tokenizer & special tokens --------------------\n",
        "MODEL_NAME = \"yiyanghkust/finbert-pretrain\"\n",
        "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Add entity marker tokens (if not present)\n",
        "special_tokens = [\"[E1]\",\"[/E1]\",\"[E2]\",\"[/E2]\"]\n",
        "tokenizer.add_tokens([t for t in special_tokens if t not in tokenizer.get_vocab()])\n",
        "print(\"Vocab size after adding special tokens:\", len(tokenizer))\n",
        "\n",
        "# -------------------- Helpers to read raw finred-style txt into same converted format --------------------\n",
        "def parse_finred_txt_line(line):\n",
        "    # Input line format: sentence | head ; tail ; relation | head ; tail ; relation ...\n",
        "    parts = [p.strip() for p in line.strip().split(\"|\")]\n",
        "    text = parts[0]\n",
        "    triples = []\n",
        "    for p in parts[1:]:\n",
        "        if not p:\n",
        "            continue\n",
        "        pieces = [x.strip() for x in p.split(\";\") if x.strip() != \"\"]\n",
        "        if len(pieces) != 3:\n",
        "            continue\n",
        "        h, t, r = pieces\n",
        "        triples.append((h,t,r))\n",
        "    return {\"text\": text, \"triples\": triples}\n",
        "\n",
        "def load_finred_converted_json(json_path):\n",
        "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "    # Convert to consistent structure: text, entities list with token spans, relations with type and head/tail token spans\n",
        "    # Already in that format for your file; just return\n",
        "    return data\n",
        "\n",
        "def load_finred_txt_as_converted(txt_path):\n",
        "    recs = []\n",
        "    if not txt_path.exists():\n",
        "        return recs\n",
        "    with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for ln in f:\n",
        "            if not ln.strip():\n",
        "                continue\n",
        "            parsed = parse_finred_txt_line(ln)\n",
        "            # Convert to tokens & offsets using tokenizer to get entity token spans\n",
        "            text = parsed[\"text\"]\n",
        "            enc = tokenizer(text, return_offsets_mapping=True, add_special_tokens=False)\n",
        "            offsets = enc[\"offset_mapping\"]\n",
        "            tokens = tokenizer.convert_ids_to_tokens(enc[\"input_ids\"])\n",
        "            # Build mapping char->token index using offsets\n",
        "            # For each triple in parsed[\"triples\"], find token spans for head and tail using naive find\n",
        "            entities = []\n",
        "            rels = []\n",
        "            # We'll create entities dict keyed by entity text to store token spans\n",
        "            ent_dict = {}\n",
        "            for (h,t,r) in parsed[\"triples\"]:\n",
        "                # head\n",
        "                if h not in ent_dict:\n",
        "                    pos = text.lower().find(h.lower())\n",
        "                    if pos != -1:\n",
        "                        start_char = pos\n",
        "                        end_char = pos + len(h)\n",
        "                        ts = None; te = None\n",
        "                        for i,(s,e) in enumerate(offsets):\n",
        "                            if s <= start_char < e:\n",
        "                                ts = i\n",
        "                            if s < end_char <= e:\n",
        "                                te = i\n",
        "                        if ts is not None and te is not None:\n",
        "                            ent_dict[h] = {\"type\":\"ENTITY\", \"start\": ts, \"end\": te}\n",
        "                # tail\n",
        "                if t not in ent_dict:\n",
        "                    pos = text.lower().find(t.lower())\n",
        "                    if pos != -1:\n",
        "                        start_char = pos\n",
        "                        end_char = pos + len(t)\n",
        "                        ts = None; te = None\n",
        "                        for i,(s,e) in enumerate(offsets):\n",
        "                            if s <= start_char < e:\n",
        "                                ts = i\n",
        "                            if s < end_char <= e:\n",
        "                                te = i\n",
        "                        if ts is not None and te is not None:\n",
        "                            ent_dict[t] = {\"type\":\"ENTITY\", \"start\": ts, \"end\": te}\n",
        "                # if both found, add relation\n",
        "                if (h in ent_dict) and (t in ent_dict):\n",
        "                    rels.append({\"type\": r, \"head\": [ent_dict[h][\"start\"], ent_dict[h][\"end\"]], \"tail\": [ent_dict[t][\"start\"], ent_dict[t][\"end\"]]})\n",
        "            # Build final record\n",
        "            recs.append({\n",
        "                \"text\": text,\n",
        "                \"tokens\": tokens,\n",
        "                \"entities\": list(ent_dict.values()),\n",
        "                \"relations\": rels\n",
        "            })\n",
        "    return recs\n",
        "\n",
        "# -------------------- Build dataset of entity-pair classification examples --------------------\n",
        "def build_pair_examples_from_converted_records(records):\n",
        "    examples = []\n",
        "    for rec in records:\n",
        "        text = rec[\"text\"]\n",
        "        entities = rec.get(\"entities\", [])\n",
        "        relations = rec.get(\"relations\", [])\n",
        "        # Build lookup from (head span tuple, tail span tuple) -> relation_type (if multiple relations, we keep all but pick first)\n",
        "        rel_lookup = {}\n",
        "        for r in relations:\n",
        "            head_span = tuple(r[\"head\"])\n",
        "            tail_span = tuple(r[\"tail\"])\n",
        "            rel_lookup[(head_span, tail_span)] = r[\"type\"]\n",
        "        # We need the entity textual strings to put markers; we will recover them by using tokenization with offsets\n",
        "        enc = tokenizer(text, return_offsets_mapping=True, add_special_tokens=False)\n",
        "        offsets = enc[\"offset_mapping\"]\n",
        "        tokens = tokenizer.convert_ids_to_tokens(enc[\"input_ids\"])\n",
        "        # extract entity text by token spans\n",
        "        ent_texts = []\n",
        "        # It's possible entities list contains only token spans without original text; so get text from offsets\n",
        "        for e in entities:\n",
        "            s_tok, e_tok = e[\"start\"], e[\"end\"]\n",
        "            if s_tok < 0 or e_tok >= len(offsets):\n",
        "                ent_texts.append(\"\")\n",
        "                continue\n",
        "            start_char = offsets[s_tok][0]\n",
        "            end_char = offsets[e_tok][1]\n",
        "            ent_text = text[start_char:end_char]\n",
        "            ent_texts.append(ent_text)\n",
        "        # Build list of entity spans with text\n",
        "        entity_items = []\n",
        "        for i,e in enumerate(entities):\n",
        "            entity_items.append({\"start\": e[\"start\"], \"end\": e[\"end\"], \"text\": ent_texts[i]})\n",
        "\n",
        "        # Create all ordered pairs of entities (head->tail). You may want to skip identical entities.\n",
        "        for i_head, head in enumerate(entity_items):\n",
        "            for i_tail, tail in enumerate(entity_items):\n",
        "                if i_head == i_tail:\n",
        "                    continue\n",
        "                # label\n",
        "                head_span = (head[\"start\"], head[\"end\"])\n",
        "                tail_span = (tail[\"start\"], tail[\"end\"])\n",
        "                lbl = rel_lookup.get((head_span, tail_span), \"no_relation\")\n",
        "                examples.append({\n",
        "                    \"text\": text,\n",
        "                    \"head\": head,\n",
        "                    \"tail\": tail,\n",
        "                    \"label\": lbl\n",
        "                })\n",
        "    return examples\n",
        "\n",
        "# -------------------- Load datasets --------------------\n",
        "train_records = load_finred_converted_json(TRAIN_JSON)\n",
        "dev_records = load_finred_txt_as_converted(DEV_TXT)    # this returns records similar to converted\n",
        "test_records = load_finred_txt_as_converted(TEST_TXT)\n",
        "\n",
        "print(f\"Loaded: train {len(train_records)} records, dev {len(dev_records)}, test {len(test_records)}\")\n",
        "\n",
        "train_examples = build_pair_examples_from_converted_records(train_records)\n",
        "dev_examples = build_pair_examples_from_converted_records(dev_records)\n",
        "test_examples = build_pair_examples_from_converted_records(test_records)\n",
        "\n",
        "print(\"Example counts (pairs):\", len(train_examples), len(dev_examples), len(test_examples))\n",
        "\n",
        "# A small sanity check - ensure some examples exist\n",
        "if len(train_examples) == 0:\n",
        "    raise RuntimeError(\"No training examples created — check conversion / entity spans.\")\n",
        "\n",
        "# -------------------- PyTorch Dataset --------------------\n",
        "class PairRelDataset(Dataset):\n",
        "    def __init__(self, examples, tokenizer, label2id, max_len=256):\n",
        "        self.examples = examples\n",
        "        self.tokenizer = tokenizer\n",
        "        self.label2id = label2id\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ex = self.examples[idx]\n",
        "        text = ex[\"text\"]\n",
        "        # We will create input by inserting special tokens around entity text spans in the original text.\n",
        "        # To be robust when entity texts appear multiple times, we use token-level indices rather than naive replace:\n",
        "        # Build tokenized representation and mark tokens between head.start..head.end etc.\n",
        "        enc = self.tokenizer(text, return_offsets_mapping=False, add_special_tokens=False)\n",
        "        input_ids = enc[\"input_ids\"]\n",
        "        tokens = self.tokenizer.convert_ids_to_tokens(input_ids)\n",
        "\n",
        "        # We'll rebuild a token-level sequence with markers\n",
        "        # First get tokens using tokenizer with add_special_tokens=False to get consistent mapping\n",
        "        enc2 = self.tokenizer(text, return_offsets_mapping=True, add_special_tokens=False)\n",
        "        offsets = enc2[\"offset_mapping\"]\n",
        "        # Build token list that we will modify by inserting marker tokens\n",
        "        token_list = self.tokenizer.convert_ids_to_tokens(enc2[\"input_ids\"])\n",
        "        # Insert markers at token positions (note: insert from back to front to preserve indices)\n",
        "        head_s, head_e = ex[\"head\"][\"start\"], ex[\"head\"][\"end\"]\n",
        "        tail_s, tail_e = ex[\"tail\"][\"start\"], ex[\"tail\"][\"end\"]\n",
        "        # We'll add markers around head (E1) and tail (E2). Insert end markers first.\n",
        "        # Insert in descending order of insert index\n",
        "        inserts = [\n",
        "            (head_e+1, \"[/E1]\"),\n",
        "            (head_s, \"[E1]\"),\n",
        "            (tail_e+1, \"[/E2]\"),\n",
        "            (tail_s, \"[E2]\")\n",
        "        ]\n",
        "        # Sort by position descending and insert\n",
        "        inserts = sorted(inserts, key=lambda x: x[0], reverse=True)\n",
        "        for pos, tok in inserts:\n",
        "            if pos < 0:\n",
        "                pos = 0\n",
        "            if pos > len(token_list):\n",
        "                pos = len(token_list)\n",
        "            token_list.insert(pos, tok)\n",
        "        # Now convert tokens back to input ids using tokenizer.convert_tokens_to_ids (handles new tokens)\n",
        "        input_ids_marked = tokenizer.convert_tokens_to_ids(token_list)\n",
        "        # Add [CLS] and [SEP]\n",
        "        input_ids_marked = [tokenizer.cls_token_id] + input_ids_marked + [tokenizer.sep_token_id]\n",
        "        # Truncate/pad\n",
        "        if len(input_ids_marked) > self.max_len:\n",
        "            input_ids_marked = input_ids_marked[:self.max_len-1] + [tokenizer.sep_token_id]\n",
        "        attention_mask = [1]*len(input_ids_marked)\n",
        "        # pad\n",
        "        pad_len = self.max_len - len(input_ids_marked)\n",
        "        if pad_len > 0:\n",
        "            input_ids_marked = input_ids_marked + [tokenizer.pad_token_id]*pad_len\n",
        "            attention_mask = attention_mask + [0]*pad_len\n",
        "\n",
        "        label_id = self.label2id.get(ex[\"label\"], self.label2id[\"no_relation\"])\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(input_ids_marked, dtype=torch.long),\n",
        "            \"attention_mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
        "            \"label\": torch.tensor(label_id, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# -------------------- Create DataLoaders --------------------\n",
        "BATCH_SIZE = 8\n",
        "train_dataset = PairRelDataset(train_examples, tokenizer, label2id, max_len=256)\n",
        "dev_dataset = PairRelDataset(dev_examples, tokenizer, label2id, max_len=256)\n",
        "test_dataset = PairRelDataset(test_examples, tokenizer, label2id, max_len=256)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# -------------------- Model setup --------------------\n",
        "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(label_list))\n",
        "# Resize token embeddings because we added special tokens\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.to(DEVICE)\n",
        "\n",
        "# Optimizer + scheduler\n",
        "EPOCHS = 1\n",
        "total_steps = len(train_loader) * EPOCHS\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(0.1*total_steps), num_training_steps=total_steps)\n",
        "\n",
        "# -------------------- Training loop (1 epoch) --------------------\n",
        "model.train()\n",
        "global_step = 0\n",
        "for epoch in range(EPOCHS):\n",
        "    loop = tqdm.tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\")\n",
        "    for batch in loop:\n",
        "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "        labels = batch[\"label\"].to(DEVICE)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        global_step += 1\n",
        "        loop.set_postfix({\"loss\": loss.item()})\n",
        "\n",
        "# Save checkpoint\n",
        "model.save_pretrained(str(OUTPUT_DIR))\n",
        "tokenizer.save_pretrained(str(OUTPUT_DIR))\n",
        "print(\"Saved model to\", OUTPUT_DIR)\n",
        "\n",
        "# -------------------- Evaluation helper --------------------\n",
        "def evaluate_model(model, dataloader, label_list, id2label, device):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    golds = []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm.tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            batch_preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "            batch_labels = labels.cpu().numpy()\n",
        "            preds.extend(batch_preds.tolist())\n",
        "            golds.extend(batch_labels.tolist())\n",
        "    # Compute metrics\n",
        "    p_micro, r_micro, f_micro, _ = precision_recall_fscore_support(golds, preds, average='micro', zero_division=0)\n",
        "    p_macro, r_macro, f_macro, _ = precision_recall_fscore_support(golds, preds, average='macro', zero_division=0)\n",
        "    # Compute per-class (also useful)\n",
        "    per_label = precision_recall_fscore_support(golds, preds, labels=list(range(len(label_list))), zero_division=0)\n",
        "    metrics = {\n",
        "        \"micro\": (p_micro, r_micro, f_micro),\n",
        "        \"macro\": (p_macro, r_macro, f_macro),\n",
        "        \"per_label\": per_label\n",
        "    }\n",
        "    return metrics, preds, golds\n",
        "\n",
        "# -------------------- Run evaluation on dev and test --------------------\n",
        "dev_metrics, dev_preds, dev_golds = evaluate_model(model, dev_loader, label_list, id2label, DEVICE)\n",
        "test_metrics, test_preds, test_golds = evaluate_model(model, test_loader, label_list, id2label, DEVICE)\n",
        "\n",
        "print(\"\\nDEV micro P/R/F:\", dev_metrics[\"micro\"])\n",
        "print(\"DEV macro P/R/F:\", dev_metrics[\"macro\"])\n",
        "print(\"\\nTEST micro P/R/F:\", test_metrics[\"micro\"])\n",
        "print(\"TEST macro P/R/F:\", test_metrics[\"macro\"])\n",
        "\n",
        "# Print sample confusion-ish info for top few labels\n",
        "from collections import defaultdict\n",
        "def print_top_label_stats(preds, golds, id2label, top_n=10):\n",
        "    counts = defaultdict(lambda: {\"tp\":0,\"fp\":0,\"fn\":0})\n",
        "    for p,g in zip(preds,golds):\n",
        "        if p==g:\n",
        "            counts[id2label[g]][\"tp\"] += 1\n",
        "        else:\n",
        "            counts[id2label[p]][\"fp\"] += 1\n",
        "            counts[id2label[g]][\"fn\"] += 1\n",
        "    # sort by total occurrences\n",
        "    items = sorted(counts.items(), key=lambda x: -(x[1][\"tp\"]+x[1][\"fn\"]))\n",
        "    print(\"\\nTop labels stats (label, tp, fp, fn):\")\n",
        "    for label,vals in items[:top_n]:\n",
        "        print(label, vals[\"tp\"], vals[\"fp\"], vals[\"fn\"])\n",
        "\n",
        "print_top_label_stats(dev_preds, dev_golds, id2label)\n",
        "print_top_label_stats(test_preds, test_golds, id2label)\n",
        "\n",
        "# -------------------- Save predictions (optional) --------------------\n",
        "pred_out = {\n",
        "    \"dev\": [{\"pred\": id2label[p], \"gold\": id2label[g]} for p,g in zip(dev_preds, dev_golds)],\n",
        "    \"test\": [{\"pred\": id2label[p], \"gold\": id2label[g]} for p,g in zip(test_preds, test_golds)]\n",
        "}\n",
        "with open(OUTPUT_DIR / \"predictions_summary.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(pred_out, f, indent=2)\n",
        "\n",
        "print(\"Predictions saved to\", OUTPUT_DIR / \"predictions_summary.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "HxZgWA49-cBR",
        "outputId": "667934e7-c0b2-4063-af4f-1bb6c4cc8695"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using device: cuda\n",
            "Labels: ['no_relation', 'brand', 'business division', 'business_division', 'chairperson', 'chief executive officer', 'chief_executive_officer', 'creator', 'currency', 'developer', 'director/manager', 'director_/_manager', 'distributed by', 'distributed_by', 'distribution format', 'distribution_format', 'employer', 'founded by', 'founded_by', 'headquarters location', 'headquarters_location', 'industry', 'legal form', 'legal_form', 'location of formation', 'location_of_formation', 'manufacturer', 'member of', 'member_of', 'operator', 'original broadcaster', 'original_broadcaster', 'owned by', 'owned_by', 'owner of', 'owner_of', 'parent organization', 'parent_organization', 'platform', 'position held', 'position_held', 'product/material produced', 'product_or_material_produced', 'publisher', 'stock exchange', 'stock_exchange', 'subsidiary']\n",
            "Vocab size after adding special tokens: 30877\n",
            "Loaded: train 5700 records, dev 1007, test 1068\n",
            "Example counts (pairs): 17024 3758 2672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at yiyanghkust/finbert-pretrain and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Training Epoch 1:   1%|          | 12/2128 [00:05<15:30,  2.27it/s, loss=4.13]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3493479138.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_by_lr_sched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m                             )\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    245\u001b[0m             )\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    248\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== FULL TRAIN/VAL/EVAL SCRIPT (WITH CLASS IMBALANCE FIXES) =====\n",
        "# Mount Drive (if not already mounted)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# Imports\n",
        "import json\n",
        "from pathlib import Path\n",
        "from collections import defaultdict, Counter\n",
        "import random, os, tqdm\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# -------------------- USER PATHS (update if needed) --------------------\n",
        "BASE_DRIVE = Path(\"/content/drive/MyDrive/Datasets_EE782_course_project/FinRED_dataset\")\n",
        "TRAIN_JSON = BASE_DRIVE / \"finred_tplinkertrain.json\"   # converted train JSON\n",
        "DEV_TXT   = BASE_DRIVE / \"finred_dev.txt\"               # finred-style dev file (raw)\n",
        "TEST_TXT  = BASE_DRIVE / \"finred_test.txt\"              # finred-style test file (raw)\n",
        "RELATIONS_LIST = BASE_DRIVE / \"finred_relations.txt\"    # optional file with relation names (one per line)\n",
        "OUTPUT_DIR = BASE_DRIVE / \"finbert_pair_class_model_balanced\"\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "# -------------------- Helpers & Loading relations --------------------\n",
        "def load_relation_set(train_json_path, relations_file=None):\n",
        "    rels = set()\n",
        "    if relations_file and relations_file.exists():\n",
        "        with open(relations_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            for ln in f:\n",
        "                r = ln.strip()\n",
        "                if r:\n",
        "                    rels.add(r)\n",
        "    if train_json_path.exists():\n",
        "        with open(train_json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "            for rec in data:\n",
        "                for rel in rec.get(\"relations\", []):\n",
        "                    rels.add(rel[\"type\"])\n",
        "    rels = sorted(rels)\n",
        "    if \"no_relation\" not in rels:\n",
        "        rels = [\"no_relation\"] + rels\n",
        "    return rels\n",
        "\n",
        "label_list = load_relation_set(TRAIN_JSON, RELATIONS_LIST)\n",
        "label2id = {l:i for i,l in enumerate(label_list)}\n",
        "id2label = {i:l for l,i in label2id.items()}\n",
        "print(\"Labels ({}): {}\".format(len(label_list), label_list))\n",
        "\n",
        "# -------------------- Tokenizer & special tokens --------------------\n",
        "MODEL_NAME = \"yiyanghkust/finbert-pretrain\"\n",
        "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
        "special_tokens = [\"[E1]\",\"[/E1]\",\"[E2]\",\"[/E2]\"]\n",
        "tokenizer.add_tokens([t for t in special_tokens if t not in tokenizer.get_vocab()])\n",
        "print(\"Vocab size after adding special tokens:\", len(tokenizer))\n",
        "\n",
        "# -------------------- Parsing functions (same as your pipeline) --------------------\n",
        "def parse_finred_txt_line(line):\n",
        "    parts = [p.strip() for p in line.strip().split(\"|\")]\n",
        "    text = parts[0]\n",
        "    triples = []\n",
        "    for p in parts[1:]:\n",
        "        if not p:\n",
        "            continue\n",
        "        pieces = [x.strip() for x in p.split(\";\") if x.strip() != \"\"]\n",
        "        if len(pieces) != 3:\n",
        "            continue\n",
        "        h, t, r = pieces\n",
        "        triples.append((h,t,r))\n",
        "    return {\"text\": text, \"triples\": triples}\n",
        "\n",
        "def load_finred_converted_json(json_path):\n",
        "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "def load_finred_txt_as_converted(txt_path):\n",
        "    recs = []\n",
        "    if not txt_path.exists():\n",
        "        return recs\n",
        "    with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for ln in f:\n",
        "            if not ln.strip():\n",
        "                continue\n",
        "            parsed = parse_finred_txt_line(ln)\n",
        "            text = parsed[\"text\"]\n",
        "            enc = tokenizer(text, return_offsets_mapping=True, add_special_tokens=False)\n",
        "            offsets = enc[\"offset_mapping\"]\n",
        "            tokens = tokenizer.convert_ids_to_tokens(enc[\"input_ids\"])\n",
        "            ent_dict = {}\n",
        "            rels = []\n",
        "            for (h,t,r) in parsed[\"triples\"]:\n",
        "                if h not in ent_dict:\n",
        "                    pos = text.lower().find(h.lower())\n",
        "                    if pos != -1:\n",
        "                        start_char = pos\n",
        "                        end_char = pos + len(h)\n",
        "                        ts = te = None\n",
        "                        for i,(s,e) in enumerate(offsets):\n",
        "                            if s <= start_char < e:\n",
        "                                ts = i\n",
        "                            if s < end_char <= e:\n",
        "                                te = i\n",
        "                        if ts is not None and te is not None:\n",
        "                            ent_dict[h] = {\"type\":\"ENTITY\", \"start\": ts, \"end\": te}\n",
        "                if t not in ent_dict:\n",
        "                    pos = text.lower().find(t.lower())\n",
        "                    if pos != -1:\n",
        "                        start_char = pos\n",
        "                        end_char = pos + len(t)\n",
        "                        ts = te = None\n",
        "                        for i,(s,e) in enumerate(offsets):\n",
        "                            if s <= start_char < e:\n",
        "                                ts = i\n",
        "                            if s < end_char <= e:\n",
        "                                te = i\n",
        "                        if ts is not None and te is not None:\n",
        "                            ent_dict[t] = {\"type\":\"ENTITY\", \"start\": ts, \"end\": te}\n",
        "                if (h in ent_dict) and (t in ent_dict):\n",
        "                    rels.append({\"type\": r, \"head\": [ent_dict[h][\"start\"], ent_dict[h][\"end\"]], \"tail\": [ent_dict[t][\"start\"], ent_dict[t][\"end\"]]})\n",
        "            recs.append({\n",
        "                \"text\": text,\n",
        "                \"tokens\": tokens,\n",
        "                \"entities\": list(ent_dict.values()),\n",
        "                \"relations\": rels\n",
        "            })\n",
        "    return recs\n",
        "\n",
        "def build_pair_examples_from_converted_records(records):\n",
        "    examples = []\n",
        "    for rec in records:\n",
        "        text = rec[\"text\"]\n",
        "        entities = rec.get(\"entities\", [])\n",
        "        relations = rec.get(\"relations\", [])\n",
        "        rel_lookup = {}\n",
        "        for r in relations:\n",
        "            head_span = tuple(r[\"head\"])\n",
        "            tail_span = tuple(r[\"tail\"])\n",
        "            rel_lookup[(head_span, tail_span)] = r[\"type\"]\n",
        "        enc = tokenizer(text, return_offsets_mapping=True, add_special_tokens=False)\n",
        "        offsets = enc[\"offset_mapping\"]\n",
        "        tokens = tokenizer.convert_ids_to_tokens(enc[\"input_ids\"])\n",
        "        ent_texts = []\n",
        "        for e in entities:\n",
        "            s_tok, e_tok = e[\"start\"], e[\"end\"]\n",
        "            if s_tok < 0 or e_tok >= len(offsets):\n",
        "                ent_texts.append(\"\")\n",
        "                continue\n",
        "            start_char = offsets[s_tok][0]\n",
        "            end_char = offsets[e_tok][1]\n",
        "            ent_text = text[start_char:end_char]\n",
        "            ent_texts.append(ent_text)\n",
        "        entity_items = []\n",
        "        for i,e in enumerate(entities):\n",
        "            entity_items.append({\"start\": e[\"start\"], \"end\": e[\"end\"], \"text\": ent_texts[i]})\n",
        "        for i_head, head in enumerate(entity_items):\n",
        "            for i_tail, tail in enumerate(entity_items):\n",
        "                if i_head == i_tail:\n",
        "                    continue\n",
        "                head_span = (head[\"start\"], head[\"end\"])\n",
        "                tail_span = (tail[\"start\"], tail[\"end\"])\n",
        "                lbl = rel_lookup.get((head_span, tail_span), \"no_relation\")\n",
        "                examples.append({\n",
        "                    \"text\": text,\n",
        "                    \"head\": head,\n",
        "                    \"tail\": tail,\n",
        "                    \"label\": lbl\n",
        "                })\n",
        "    return examples\n",
        "\n",
        "# -------------------- Load datasets --------------------\n",
        "train_records = load_finred_converted_json(TRAIN_JSON)\n",
        "dev_records = load_finred_txt_as_converted(DEV_TXT)\n",
        "test_records = load_finred_txt_as_converted(TEST_TXT)\n",
        "\n",
        "print(f\"Loaded: train {len(train_records)} records, dev {len(dev_records)}, test {len(test_records)}\")\n",
        "\n",
        "train_examples = build_pair_examples_from_converted_records(train_records)\n",
        "dev_examples = build_pair_examples_from_converted_records(dev_records)\n",
        "test_examples = build_pair_examples_from_converted_records(test_records)\n",
        "\n",
        "print(\"Pair example counts (train/dev/test):\", len(train_examples), len(dev_examples), len(test_examples))\n",
        "if len(train_examples) == 0:\n",
        "    raise RuntimeError(\"No training examples created — check conversion / entity spans.\")\n",
        "\n",
        "# -------------------- Compute class frequencies & sampler weights --------------------\n",
        "train_labels = [ex[\"label\"] for ex in train_examples]\n",
        "label_counts = Counter(train_labels)\n",
        "print(\"Train label counts (top 20):\", label_counts.most_common(20))\n",
        "\n",
        "# inverse frequency for class weights (for loss)\n",
        "class_freqs = np.array([label_counts.get(lbl, 0) for lbl in label_list], dtype=np.float32)\n",
        "# Avoid division by zero\n",
        "class_freqs[class_freqs == 0] = 1.0\n",
        "inv_freq = 1.0 / class_freqs\n",
        "# Normalize (not necessary but keep scale stable)\n",
        "inv_freq = inv_freq / inv_freq.sum() * len(inv_freq)\n",
        "class_weights = torch.tensor(inv_freq, dtype=torch.float32)\n",
        "\n",
        "# Per-sample weights for WeightedRandomSampler: weight = 1 / count(label)\n",
        "sample_weights = [1.0 / label_counts[lab] if label_counts.get(lab,0)>0 else 0.0 for lab in train_labels]\n",
        "sample_weights = torch.DoubleTensor(sample_weights)\n",
        "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "print(\"Class weights (used in loss):\", {lbl: float(class_weights[i]) for i,lbl in enumerate(label_list)})\n",
        "\n",
        "# -------------------- PyTorch Dataset --------------------\n",
        "class PairRelDataset(Dataset):\n",
        "    def __init__(self, examples, tokenizer, label2id, max_len=256):\n",
        "        self.examples = examples\n",
        "        self.tokenizer = tokenizer\n",
        "        self.label2id = label2id\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ex = self.examples[idx]\n",
        "        text = ex[\"text\"]\n",
        "        enc2 = self.tokenizer(text, return_offsets_mapping=True, add_special_tokens=False)\n",
        "        offsets = enc2[\"offset_mapping\"]\n",
        "        token_list = self.tokenizer.convert_ids_to_tokens(enc2[\"input_ids\"])\n",
        "        head_s, head_e = ex[\"head\"][\"start\"], ex[\"head\"][\"end\"]\n",
        "        tail_s, tail_e = ex[\"tail\"][\"start\"], ex[\"tail\"][\"end\"]\n",
        "        inserts = [\n",
        "            (head_e+1, \"[/E1]\"),\n",
        "            (head_s, \"[E1]\"),\n",
        "            (tail_e+1, \"[/E2]\"),\n",
        "            (tail_s, \"[E2]\")\n",
        "        ]\n",
        "        inserts = sorted(inserts, key=lambda x: x[0], reverse=True)\n",
        "        for pos, tok in inserts:\n",
        "            if pos < 0:\n",
        "                pos = 0\n",
        "            if pos > len(token_list):\n",
        "                pos = len(token_list)\n",
        "            token_list.insert(pos, tok)\n",
        "        input_ids_marked = tokenizer.convert_tokens_to_ids(token_list)\n",
        "        input_ids_marked = [tokenizer.cls_token_id] + input_ids_marked + [tokenizer.sep_token_id]\n",
        "        if len(input_ids_marked) > self.max_len:\n",
        "            input_ids_marked = input_ids_marked[:self.max_len-1] + [tokenizer.sep_token_id]\n",
        "        attention_mask = [1]*len(input_ids_marked)\n",
        "        pad_len = self.max_len - len(input_ids_marked)\n",
        "        if pad_len > 0:\n",
        "            input_ids_marked = input_ids_marked + [tokenizer.pad_token_id]*pad_len\n",
        "            attention_mask = attention_mask + [0]*pad_len\n",
        "        label_id = self.label2id.get(ex[\"label\"], self.label2id[\"no_relation\"])\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(input_ids_marked, dtype=torch.long),\n",
        "            \"attention_mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
        "            \"label\": torch.tensor(label_id, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Create datasets and loaders; use sampler for train_loader to balance classes\n",
        "BATCH_SIZE = 8\n",
        "train_dataset = PairRelDataset(train_examples, tokenizer, label2id, max_len=256)\n",
        "dev_dataset = PairRelDataset(dev_examples, tokenizer, label2id, max_len=256)\n",
        "test_dataset = PairRelDataset(test_examples, tokenizer, label2id, max_len=256)\n",
        "\n",
        "# train_loader uses sampler; dev/test use default sequential loader\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# -------------------- Model setup --------------------\n",
        "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(label_list))\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.to(DEVICE)\n",
        "\n",
        "# Criterion with class weights\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights.to(DEVICE))\n",
        "\n",
        "# Optimizer + scheduler\n",
        "EPOCHS = 3\n",
        "total_steps = len(train_loader) * EPOCHS\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=max(1,int(0.1*total_steps)), num_training_steps=total_steps)\n",
        "\n",
        "# -------------------- Training loop (3 epochs) --------------------\n",
        "history = {\"train_loss\": [], \"dev_loss\": [], \"dev_metrics\": None, \"test_metrics\": None}\n",
        "model.train()\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    step = 0\n",
        "    loop = tqdm.tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} (train)\")\n",
        "    for batch in loop:\n",
        "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "        labels = batch[\"label\"].to(DEVICE)\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        running_loss += loss.item()\n",
        "        step += 1\n",
        "        loop.set_postfix({\"loss\": loss.item()})\n",
        "    avg_train_loss = running_loss / max(1, step)\n",
        "    history[\"train_loss\"].append(avg_train_loss)\n",
        "\n",
        "    # -------------------- Validation (compute loss + metrics) --------------------\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    val_steps = 0\n",
        "    preds = []\n",
        "    golds = []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm.tqdm(dev_loader, desc=f\"Epoch {epoch}/{EPOCHS} (dev)\"):\n",
        "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "            labels = batch[\"label\"].to(DEVICE)\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            loss = criterion(logits, labels)\n",
        "            val_running_loss += loss.item()\n",
        "            val_steps += 1\n",
        "            batch_preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "            batch_labels = labels.cpu().numpy()\n",
        "            preds.extend(batch_preds.tolist())\n",
        "            golds.extend(batch_labels.tolist())\n",
        "    avg_dev_loss = val_running_loss / max(1, val_steps)\n",
        "    history[\"dev_loss\"].append(avg_dev_loss)\n",
        "\n",
        "    # compute metrics\n",
        "    if len(golds) > 0:\n",
        "        dev_p_micro, dev_r_micro, dev_f_micro, _ = precision_recall_fscore_support(golds, preds, average='micro', zero_division=0)\n",
        "        dev_p_macro, dev_r_macro, dev_f_macro, _ = precision_recall_fscore_support(golds, preds, average='macro', zero_division=0)\n",
        "        dev_acc = accuracy_score(golds, preds)\n",
        "    else:\n",
        "        dev_p_micro = dev_r_micro = dev_f_micro = dev_p_macro = dev_r_macro = dev_f_macro = dev_acc = 0.0\n",
        "\n",
        "    history.setdefault(\"per_epoch\", []).append({\n",
        "        \"epoch\": epoch,\n",
        "        \"train_loss\": avg_train_loss,\n",
        "        \"dev_loss\": avg_dev_loss,\n",
        "        \"dev_micro\": [dev_p_micro, dev_r_micro, dev_f_micro],\n",
        "        \"dev_macro\": [dev_p_macro, dev_r_macro, dev_f_macro],\n",
        "        \"dev_accuracy\": dev_acc\n",
        "    })\n",
        "\n",
        "    print(f\"\\nEpoch {epoch} summary:\")\n",
        "    print(f\"  Train loss: {avg_train_loss:.6f}\")\n",
        "    print(f\"  Dev loss:   {avg_dev_loss:.6f}\")\n",
        "    print(f\"  Dev acc: {dev_acc:.4f}  Dev micro P/R/F: {dev_p_micro:.4f}/{dev_r_micro:.4f}/{dev_f_micro:.4f}\")\n",
        "    print(f\"  Dev macro P/R/F: {dev_p_macro:.4f}/{dev_r_macro:.4f}/{dev_f_macro:.4f}\")\n",
        "\n",
        "# -------------------- Final evaluation on dev & test (with losses) --------------------\n",
        "def evaluate_with_loss(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    golds = []\n",
        "    running_loss = 0.0\n",
        "    steps = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm.tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            loss = criterion(logits, labels)\n",
        "            running_loss += loss.item()\n",
        "            steps += 1\n",
        "            batch_preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "            batch_labels = labels.cpu().numpy()\n",
        "            preds.extend(batch_preds.tolist())\n",
        "            golds.extend(batch_labels.tolist())\n",
        "    avg_loss = running_loss / max(1, steps)\n",
        "    if len(golds) > 0:\n",
        "        p_micro, r_micro, f_micro, _ = precision_recall_fscore_support(golds, preds, average='micro', zero_division=0)\n",
        "        p_macro, r_macro, f_macro, _ = precision_recall_fscore_support(golds, preds, average='macro', zero_division=0)\n",
        "        acc = accuracy_score(golds, preds)\n",
        "    else:\n",
        "        p_micro = r_micro = f_micro = p_macro = r_macro = f_macro = acc = 0.0\n",
        "    per_label = precision_recall_fscore_support(golds, preds, labels=list(range(len(label_list))), zero_division=0) if len(golds)>0 else None\n",
        "    return {\n",
        "        \"loss\": avg_loss,\n",
        "        \"micro\": (p_micro, r_micro, f_micro),\n",
        "        \"macro\": (p_macro, r_macro, f_macro),\n",
        "        \"accuracy\": acc,\n",
        "        \"per_label\": per_label,\n",
        "        \"preds\": preds,\n",
        "        \"golds\": golds\n",
        "    }\n",
        "\n",
        "dev_eval = evaluate_with_loss(model, dev_loader, criterion, DEVICE)\n",
        "test_eval = evaluate_with_loss(model, test_loader, criterion, DEVICE)\n",
        "\n",
        "# -------------------- Save model, tokenizer, and metrics --------------------\n",
        "model.save_pretrained(str(OUTPUT_DIR))\n",
        "tokenizer.save_pretrained(str(OUTPUT_DIR))\n",
        "print(\"Saved model+tokenizer to\", OUTPUT_DIR)\n",
        "\n",
        "metrics_summary = {\n",
        "    \"labels\": label_list,\n",
        "    \"class_counts_train\": dict(label_counts),\n",
        "    \"class_weights_used\": {lbl: float(class_weights[i]) for i,lbl in enumerate(label_list)},\n",
        "    \"history\": history,\n",
        "    \"dev_eval\": {\n",
        "        \"loss\": dev_eval[\"loss\"],\n",
        "        \"accuracy\": dev_eval[\"accuracy\"],\n",
        "        \"micro_p_r_f\": dev_eval[\"micro\"],\n",
        "        \"macro_p_r_f\": dev_eval[\"macro\"]\n",
        "    },\n",
        "    \"test_eval\": {\n",
        "        \"loss\": test_eval[\"loss\"],\n",
        "        \"accuracy\": test_eval[\"accuracy\"],\n",
        "        \"micro_p_r_f\": test_eval[\"micro\"],\n",
        "        \"macro_p_r_f\": test_eval[\"macro\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(OUTPUT_DIR / \"metrics_summary.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(metrics_summary, f, indent=2)\n",
        "\n",
        "# Save per-sample predictions (small summary)\n",
        "pred_out = {\n",
        "    \"dev\": [{\"pred\": id2label[p], \"gold\": id2label[g]} for p,g in zip(dev_eval[\"preds\"], dev_eval[\"golds\"])],\n",
        "    \"test\": [{\"pred\": id2label[p], \"gold\": id2label[g]} for p,g in zip(test_eval[\"preds\"], test_eval[\"golds\"])]\n",
        "}\n",
        "with open(OUTPUT_DIR / \"predictions_summary.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(pred_out, f, indent=2)\n",
        "\n",
        "# Print final nicely formatted results\n",
        "print(\"\\n=== FINAL RESULTS ===\")\n",
        "print(\"DEV: loss={:.6f} acc={:.4f} microP/R/F={:.4f}/{:.4f}/{:.4f} macroP/R/F={:.4f}/{:.4f}/{:.4f}\".format(\n",
        "    dev_eval[\"loss\"], dev_eval[\"accuracy\"], dev_eval[\"micro\"][0], dev_eval[\"micro\"][1], dev_eval[\"micro\"][2],\n",
        "    dev_eval[\"macro\"][0], dev_eval[\"macro\"][1], dev_eval[\"macro\"][2]\n",
        "))\n",
        "print(\"TEST: loss={:.6f} acc={:.4f} microP/R/F={:.4f}/{:.4f}/{:.4f} macroP/R/F={:.4f}/{:.4f}/{:.4f}\".format(\n",
        "    test_eval[\"loss\"], test_eval[\"accuracy\"], test_eval[\"micro\"][0], test_eval[\"micro\"][1], test_eval[\"micro\"][2],\n",
        "    test_eval[\"macro\"][0], test_eval[\"macro\"][1], test_eval[\"macro\"][2]\n",
        "))\n",
        "\n",
        "print(\"\\nSaved metrics to:\", str(OUTPUT_DIR / \"metrics_summary.json\"))\n",
        "print(\"Saved predictions to:\", str(OUTPUT_DIR / \"predictions_summary.json\"))\n",
        "\n",
        "# optionally print top-per-label TP/FP/FN summary for quick debugging\n",
        "from collections import defaultdict\n",
        "def print_top_label_stats_from_preds(preds, golds, id2label, top_n=15):\n",
        "    counts = defaultdict(lambda: {\"tp\":0,\"fp\":0,\"fn\":0})\n",
        "    for p,g in zip(preds,golds):\n",
        "        if p==g:\n",
        "            counts[id2label[g]][\"tp\"] += 1\n",
        "        else:\n",
        "            counts[id2label[p]][\"fp\"] += 1\n",
        "            counts[id2label[g]][\"fn\"] += 1\n",
        "    items = sorted(counts.items(), key=lambda x: -(x[1][\"tp\"]+x[1][\"fn\"]))\n",
        "    print(\"\\nTop labels stats (label, tp, fp, fn):\")\n",
        "    for label,vals in items[:top_n]:\n",
        "        print(label, vals[\"tp\"], vals[\"fp\"], vals[\"fn\"])\n",
        "\n",
        "print_top_label_stats_from_preds(dev_eval[\"preds\"], dev_eval[\"golds\"], id2label)\n",
        "print_top_label_stats_from_preds(test_eval[\"preds\"], test_eval[\"golds\"], id2label)\n",
        "\n",
        "# End of script\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "698iRJ4OEYvc",
        "outputId": "6cf19160-a595-494d-db62-69d7ab2b4243"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using device: cuda\n",
            "Labels (47): ['no_relation', 'brand', 'business division', 'business_division', 'chairperson', 'chief executive officer', 'chief_executive_officer', 'creator', 'currency', 'developer', 'director/manager', 'director_/_manager', 'distributed by', 'distributed_by', 'distribution format', 'distribution_format', 'employer', 'founded by', 'founded_by', 'headquarters location', 'headquarters_location', 'industry', 'legal form', 'legal_form', 'location of formation', 'location_of_formation', 'manufacturer', 'member of', 'member_of', 'operator', 'original broadcaster', 'original_broadcaster', 'owned by', 'owned_by', 'owner of', 'owner_of', 'parent organization', 'parent_organization', 'platform', 'position held', 'position_held', 'product/material produced', 'product_or_material_produced', 'publisher', 'stock exchange', 'stock_exchange', 'subsidiary']\n",
            "Vocab size after adding special tokens: 30877\n",
            "Loaded: train 5700 records, dev 1007, test 1068\n",
            "Pair example counts (train/dev/test): 17024 3758 2672\n",
            "Train label counts (top 20): [('no_relation', 9982), ('product_or_material_produced', 1315), ('industry', 1153), ('headquarters_location', 558), ('owned_by', 482), ('employer', 454), ('owner_of', 385), ('parent_organization', 354), ('subsidiary', 300), ('developer', 212), ('location_of_formation', 196), ('position_held', 185), ('stock_exchange', 159), ('manufacturer', 152), ('chairperson', 147), ('operator', 132), ('chief_executive_officer', 102), ('founded_by', 101), ('legal_form', 96), ('original_broadcaster', 72)]\n",
            "Class weights (used in loss): {'no_relation': 0.00027156155556440353, 'brand': 0.04443814978003502, 'business division': 2.7107272148132324, 'business_division': 0.12321487814188004, 'chairperson': 0.01844032108783722, 'chief executive officer': 2.7107272148132324, 'chief_executive_officer': 0.026575759053230286, 'creator': 0.047556620091199875, 'currency': 0.04107162728905678, 'developer': 0.012786449864506721, 'director/manager': 2.7107272148132324, 'director_/_manager': 0.08471022546291351, 'distributed by': 2.7107272148132324, 'distributed_by': 0.04443814978003502, 'distribution format': 2.7107272148132324, 'distribution_format': 0.04235511273145676, 'employer': 0.00597076490521431, 'founded by': 2.7107272148132324, 'founded_by': 0.026838883757591248, 'headquarters location': 2.7107272148132324, 'headquarters_location': 0.004857934080064297, 'industry': 0.002351021161302924, 'legal form': 2.7107272148132324, 'legal_form': 0.028236743062734604, 'location of formation': 2.7107272148132324, 'location_of_formation': 0.013830240815877914, 'manufacturer': 0.017833733931183815, 'member of': 2.7107272148132324, 'member_of': 0.06160743907094002, 'operator': 0.02053581364452839, 'original broadcaster': 2.7107272148132324, 'original_broadcaster': 0.037648990750312805, 'owned by': 2.7107272148132324, 'owned_by': 0.0056239161640405655, 'owner of': 2.7107272148132324, 'owner_of': 0.007040849886834621, 'parent organization': 2.7107272148132324, 'parent_organization': 0.007657421752810478, 'platform': 0.05212937295436859, 'position held': 2.7107272148132324, 'position_held': 0.01465258002281189, 'product/material produced': 2.7107272148132324, 'product_or_material_produced': 0.002061389619484544, 'publisher': 0.0968116968870163, 'stock exchange': 2.7107272148132324, 'stock_exchange': 0.01704859919846058, 'subsidiary': 0.00903575774282217}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at yiyanghkust/finbert-pretrain and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 1/3 (train): 100%|██████████| 2128/2128 [13:13<00:00,  2.68it/s, loss=0.0816]\n",
            "Epoch 1/3 (dev): 100%|██████████| 470/470 [00:57<00:00,  8.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 summary:\n",
            "  Train loss: 1.136054\n",
            "  Dev loss:   2.764741\n",
            "  Dev acc: 0.1770  Dev micro P/R/F: 0.1770/0.1770/0.1770\n",
            "  Dev macro P/R/F: 0.2319/0.5831/0.2925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3 (train): 100%|██████████| 2128/2128 [13:10<00:00,  2.69it/s, loss=0.0567]\n",
            "Epoch 2/3 (dev): 100%|██████████| 470/470 [00:57<00:00,  8.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2 summary:\n",
            "  Train loss: 0.108177\n",
            "  Dev loss:   2.483149\n",
            "  Dev acc: 0.2257  Dev micro P/R/F: 0.2257/0.2257/0.2257\n",
            "  Dev macro P/R/F: 0.2710/0.6305/0.3504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3 (train): 100%|██████████| 2128/2128 [13:10<00:00,  2.69it/s, loss=0.00674]\n",
            "Epoch 3/3 (dev): 100%|██████████| 470/470 [00:57<00:00,  8.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3 summary:\n",
            "  Train loss: 0.052654\n",
            "  Dev loss:   2.341749\n",
            "  Dev acc: 0.2347  Dev micro P/R/F: 0.2347/0.2347/0.2347\n",
            "  Dev macro P/R/F: 0.2803/0.6249/0.3710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 470/470 [00:57<00:00,  8.16it/s]\n",
            "Evaluating: 100%|██████████| 334/334 [00:39<00:00,  8.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model+tokenizer to /content/drive/MyDrive/Datasets_EE782_course_project/FinRED_dataset/finbert_pair_class_model_balanced\n",
            "\n",
            "=== FINAL RESULTS ===\n",
            "DEV: loss=2.341749 acc=0.2347 microP/R/F=0.2347/0.2347/0.2347 macroP/R/F=0.2803/0.6249/0.3710\n",
            "TEST: loss=1.696690 acc=0.3166 microP/R/F=0.3166/0.3166/0.3166 macroP/R/F=0.3370/0.6791/0.4371\n",
            "\n",
            "Saved metrics to: /content/drive/MyDrive/Datasets_EE782_course_project/FinRED_dataset/finbert_pair_class_model_balanced/metrics_summary.json\n",
            "Saved predictions to: /content/drive/MyDrive/Datasets_EE782_course_project/FinRED_dataset/finbert_pair_class_model_balanced/predictions_summary.json\n",
            "\n",
            "Top labels stats (label, tp, fp, fn):\n",
            "no_relation 0 0 2444\n",
            "industry 168 342 42\n",
            "product_or_material_produced 143 272 63\n",
            "owned_by 76 281 37\n",
            "headquarters_location 81 174 28\n",
            "employer 59 140 20\n",
            "parent_organization 13 60 59\n",
            "subsidiary 38 66 27\n",
            "owner_of 28 69 29\n",
            "stock_exchange 51 437 0\n",
            "position_held 36 51 14\n",
            "manufacturer 26 266 17\n",
            "location_of_formation 22 36 13\n",
            "legal_form 13 244 15\n",
            "founded_by 5 42 20\n",
            "\n",
            "Top labels stats (label, tp, fp, fn):\n",
            "no_relation 0 0 1401\n",
            "product_or_material_produced 118 210 62\n",
            "industry 131 202 38\n",
            "owned_by 80 333 44\n",
            "headquarters_location 73 151 23\n",
            "owner_of 45 85 46\n",
            "parent_organization 30 85 55\n",
            "subsidiary 41 96 42\n",
            "employer 61 119 12\n",
            "manufacturer 22 54 20\n",
            "developer 27 57 9\n",
            "location_of_formation 19 50 13\n",
            "founded_by 15 39 12\n",
            "position_held 19 32 8\n",
            "stock_exchange 25 38 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === CASREL-style pipeline (PyTorch) with FinBERT encoder ===\n",
        "# Single Colab cell: conversion -> dataset -> model -> train(3 epochs) -> eval -> save\n",
        "\n",
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# Imports\n",
        "import json, os, tqdm, math\n",
        "from pathlib import Path\n",
        "from collections import Counter, defaultdict\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from transformers import BertTokenizerFast, BertModel, BertConfig\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "# -------------------- USER PATHS --------------------\n",
        "BASE = Path(\"/content/drive/MyDrive/Datasets_EE782_course_project/FinRED_dataset\")\n",
        "# source finred-style text (your file)\n",
        "SRC_TRAIN_TXT = BASE / \"finred_train.txt\"\n",
        "SRC_DEV_TXT   = BASE / \"finred_dev.txt\"\n",
        "SRC_TEST_TXT  = BASE / \"finred_test.txt\"\n",
        "# where to store converted CASREL jsonl files\n",
        "CASREL_TRAIN = BASE / \"casrel_train.jsonl\"\n",
        "CASREL_DEV   = BASE / \"casrel_dev.jsonl\"\n",
        "CASREL_TEST  = BASE / \"casrel_test.jsonl\"\n",
        "\n",
        "OUTPUT_DIR = BASE / \"casrel_finbert_model\"\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", DEVICE)\n",
        "\n",
        "# -------------------- PARAMETERS --------------------\n",
        "MODEL_NAME = \"yiyanghkust/finbert-pretrain\"\n",
        "MAX_LEN = 128          # tune as needed; keep small for memory\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 3\n",
        "LR = 2e-5\n",
        "RANDOM_SEED = 42\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "# -------------------- Helper: parse FinRED-style line --------------------\n",
        "def parse_finred_line(line):\n",
        "    # format: sentence | head ; tail ; relation | head ; tail ; relation | ...\n",
        "    parts = [p.strip() for p in line.strip().split(\"|\")]\n",
        "    text = parts[0]\n",
        "    triples = []\n",
        "    for p in parts[1:]:\n",
        "        if not p:\n",
        "            continue\n",
        "        fields = [x.strip() for x in p.split(\";\") if x.strip() != \"\"]\n",
        "        if len(fields) != 3:\n",
        "            continue\n",
        "        h,t,r = fields\n",
        "        triples.append((h,t,r))\n",
        "    return {\"text\": text, \"triples\": triples}\n",
        "\n",
        "# -------------------- Tokenizer --------------------\n",
        "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
        "# ensure consistent tokenization for offsets: use add_special_tokens=False when mapping spans\n",
        "\n",
        "# -------------------- Convert FinRED -> CASREL JSONL --------------------\n",
        "# CASREL JSON structure per line:\n",
        "# { \"text\": \"...\", \"tokens\": [...], \"spo_list\":[{\"subject\": \"...\", \"predicate\":\"...\", \"object\":\"...\"}] }\n",
        "\n",
        "def convert_txt_to_casrel_jsonl(src_path, out_path):\n",
        "    if not src_path.exists():\n",
        "        print(f\"Source {src_path} not found — skipping conversion.\")\n",
        "        return 0\n",
        "    n = 0\n",
        "    with open(src_path, \"r\", encoding=\"utf-8\") as fr, open(out_path, \"w\", encoding=\"utf-8\") as fw:\n",
        "        for ln in fr:\n",
        "            if not ln.strip():\n",
        "                continue\n",
        "            parsed = parse_finred_line(ln)\n",
        "            text = parsed[\"text\"]\n",
        "            triples = parsed[\"triples\"]\n",
        "            # build spo_list\n",
        "            spo_list = []\n",
        "            # For subjects/objects we will store the text (not token spans) — CASREL conversion to labels happens later\n",
        "            for (h,t,r) in triples:\n",
        "                spo_list.append({\"subject\": h, \"predicate\": r, \"object\": t})\n",
        "            rec = {\"text\": text, \"spo_list\": spo_list}\n",
        "            fw.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
        "            n += 1\n",
        "    print(f\"Wrote {n} records to {out_path}\")\n",
        "    return n\n",
        "\n",
        "# Convert train/dev/test if not already converted\n",
        "convert_txt_to_casrel_jsonl(SRC_TRAIN_TXT, CASREL_TRAIN)\n",
        "convert_txt_to_casrel_jsonl(SRC_DEV_TXT, CASREL_DEV)\n",
        "convert_txt_to_casrel_jsonl(SRC_TEST_TXT, CASREL_TEST)\n",
        "\n",
        "# -------------------- Collect relation set from converted files --------------------\n",
        "def collect_relations(jsonl_paths):\n",
        "    rels = set()\n",
        "    for p in jsonl_paths:\n",
        "        if not p.exists():\n",
        "            continue\n",
        "        with open(p, \"r\", encoding=\"utf-8\") as f:\n",
        "            for ln in f:\n",
        "                rec = json.loads(ln)\n",
        "                for spo in rec.get(\"spo_list\", []):\n",
        "                    rels.add(spo[\"predicate\"])\n",
        "    rels = sorted(rels)\n",
        "    return rels\n",
        "\n",
        "relation_list = collect_relations([CASREL_TRAIN, CASREL_DEV, CASREL_TEST])\n",
        "if len(relation_list) == 0:\n",
        "    print(\"Warning: no relations found in dataset. Check input files.\")\n",
        "# create mapping\n",
        "rel2id = {r:i for i,r in enumerate(relation_list)}\n",
        "id2rel = {i:r for r,i in rel2id.items()}\n",
        "num_rels = len(relation_list)\n",
        "print(\"Number of predicates:\", num_rels)\n",
        "\n",
        "# -------------------- Dataset building: create label matrices\n",
        "# For each sample:\n",
        "#  - tokenized input_ids, attention_mask\n",
        "#  - sub_head_labels: L (0/1)\n",
        "#  - sub_tail_labels: L (0/1)\n",
        "#  - obj_head_labels: R x L  (0/1)  (object heads for each relation)\n",
        "#  - obj_tail_labels: R x L  (0/1)\n",
        "#\n",
        "# We will find token-level spans by using tokenizer offsets and .find() of subject/object in text (lowercase)\n",
        "# If multiple occurrences, use the first match (this is acceptable for FinRED typical data).\n",
        "# If any mapping fails for a triple, skip that triple.\n",
        "\n",
        "def build_casrel_records(jsonl_path, tokenizer, max_len=MAX_LEN):\n",
        "    records = []\n",
        "    if not jsonl_path.exists():\n",
        "        return records\n",
        "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for ln in f:\n",
        "            rec = json.loads(ln)\n",
        "            text = rec[\"text\"]\n",
        "            spo_list = rec.get(\"spo_list\", [])\n",
        "            # tokenize with offsets\n",
        "            enc = tokenizer(text, return_offsets_mapping=True, add_special_tokens=False)\n",
        "            offsets = enc[\"offset_mapping\"]\n",
        "            token_ids = enc[\"input_ids\"]\n",
        "            tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
        "            L = len(tokens)\n",
        "            if L == 0 or L > max_len:\n",
        "                # skip too long samples (or you could truncate intelligently)\n",
        "                continue\n",
        "            # initialize label structures\n",
        "            sub_heads = [0]*L\n",
        "            sub_tails = [0]*L\n",
        "            # objects: R x L zeros\n",
        "            obj_heads = [[0]*L for _ in range(num_rels)]\n",
        "            obj_tails = [[0]*L for _ in range(num_rels)]\n",
        "            any_spo = False\n",
        "            for spo in spo_list:\n",
        "                subj = spo[\"subject\"]\n",
        "                obj = spo[\"object\"]\n",
        "                pred = spo[\"predicate\"]\n",
        "                if pred not in rel2id:\n",
        "                    continue\n",
        "                rid = rel2id[pred]\n",
        "                # find subject char span\n",
        "                s_pos = text.lower().find(subj.lower())\n",
        "                if s_pos == -1:\n",
        "                    # skip if can't find\n",
        "                    continue\n",
        "                s_end = s_pos + len(subj)\n",
        "                # map to token indices\n",
        "                s_tok = None; s_tok_end = None\n",
        "                for i,(a,b) in enumerate(offsets):\n",
        "                    if a <= s_pos < b:\n",
        "                        s_tok = i\n",
        "                    if a < s_end <= b:\n",
        "                        s_tok_end = i\n",
        "                if s_tok is None or s_tok_end is None:\n",
        "                    continue\n",
        "                # find object char span\n",
        "                o_pos = text.lower().find(obj.lower())\n",
        "                if o_pos == -1:\n",
        "                    continue\n",
        "                o_end = o_pos + len(obj)\n",
        "                o_tok = None; o_tok_end = None\n",
        "                for i,(a,b) in enumerate(offsets):\n",
        "                    if a <= o_pos < b:\n",
        "                        o_tok = i\n",
        "                    if a < o_end <= b:\n",
        "                        o_tok_end = i\n",
        "                if o_tok is None or o_tok_end is None:\n",
        "                    continue\n",
        "                # set labels\n",
        "                sub_heads[s_tok] = 1\n",
        "                sub_tails[s_tok_end] = 1\n",
        "                obj_heads[rid][o_tok] = 1\n",
        "                obj_tails[rid][o_tok_end] = 1\n",
        "                any_spo = True\n",
        "            # Only keep records with at least one SPO mapping successfully\n",
        "            # (CASREL training needs supervision). If none mapped, we can still keep as negative sample, but simpler to keep negative too:\n",
        "            records.append({\n",
        "                \"text\": text,\n",
        "                \"tokens\": tokens,\n",
        "                \"input_ids\": token_ids,\n",
        "                \"offsets\": offsets,\n",
        "                \"sub_heads\": sub_heads,\n",
        "                \"sub_tails\": sub_tails,\n",
        "                \"obj_heads\": obj_heads,\n",
        "                \"obj_tails\": obj_tails\n",
        "            })\n",
        "    return records\n",
        "\n",
        "# Build datasets\n",
        "train_records = build_casrel_records(CASREL_TRAIN, tokenizer, max_len=MAX_LEN)\n",
        "dev_records   = build_casrel_records(CASREL_DEV, tokenizer, max_len=MAX_LEN)\n",
        "test_records  = build_casrel_records(CASREL_TEST, tokenizer, max_len=MAX_LEN)\n",
        "\n",
        "print(f\"Records: train {len(train_records)} dev {len(dev_records)} test {len(test_records)}\")\n",
        "\n",
        "# -------------------- Compute class-level positive rates for weighting --------------------\n",
        "# For subject head/tail and each relation's obj head/tail compute pos weights\n",
        "def compute_pos_weights(records):\n",
        "    # subject\n",
        "    s_heads = 0; s_total = 0\n",
        "    s_tails = 0\n",
        "    obj_counts_head = [0]*num_rels\n",
        "    obj_counts_tail = [0]*num_rels\n",
        "    total_tokens = 0\n",
        "    for r in records:\n",
        "        L = len(r[\"sub_heads\"])\n",
        "        total_tokens += L\n",
        "        s_heads += sum(r[\"sub_heads\"])\n",
        "        s_tails += sum(r[\"sub_tails\"])\n",
        "        for rid in range(num_rels):\n",
        "            obj_counts_head[rid] += sum(r[\"obj_heads\"][rid])\n",
        "            obj_counts_tail[rid] += sum(r[\"obj_tails\"][rid])\n",
        "    # compute positive weights: weight = (neg / pos) or similar; BCEWithLogits allows pos_weight\n",
        "    s_head_pos = s_heads\n",
        "    s_tail_pos = s_tails\n",
        "    s_head_neg = total_tokens - s_head_pos\n",
        "    s_tail_neg = total_tokens - s_tail_pos\n",
        "    s_head_pos_weight = (s_head_neg / (s_head_pos+1e-6)) if s_head_pos>0 else 1.0\n",
        "    s_tail_pos_weight = (s_tail_neg / (s_tail_pos+1e-6)) if s_tail_pos>0 else 1.0\n",
        "    obj_pos_weights_head = []\n",
        "    obj_pos_weights_tail = []\n",
        "    for rid in range(num_rels):\n",
        "        pos_h = obj_counts_head[rid]\n",
        "        neg_h = total_tokens - pos_h\n",
        "        pos_t = obj_counts_tail[rid]\n",
        "        neg_t = total_tokens - pos_t\n",
        "        w_h = (neg_h / (pos_h+1e-6)) if pos_h>0 else 1.0\n",
        "        w_t = (neg_t / (pos_t+1e-6)) if pos_t>0 else 1.0\n",
        "        obj_pos_weights_head.append(w_h)\n",
        "        obj_pos_weights_tail.append(w_t)\n",
        "    return {\n",
        "        \"s_head\": s_head_pos_weight,\n",
        "        \"s_tail\": s_tail_pos_weight,\n",
        "        \"obj_head\": obj_pos_weights_head,\n",
        "        \"obj_tail\": obj_pos_weights_tail\n",
        "    }\n",
        "\n",
        "weights = compute_pos_weights(train_records)\n",
        "print(\"Computed pos-weights (approx):\", weights)\n",
        "\n",
        "# -------------------- Dataset & collate (pad to batch max length) --------------------\n",
        "class CASRELDataset(Dataset):\n",
        "    def __init__(self, records, tokenizer, max_len=MAX_LEN):\n",
        "        self.records = records\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.records)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        r = self.records[idx]\n",
        "        input_ids = r[\"input_ids\"]\n",
        "        attention_mask = [1]*len(input_ids)\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
        "            \"attention_mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
        "            \"sub_head\": torch.tensor(r[\"sub_heads\"], dtype=torch.float),   # L\n",
        "            \"sub_tail\": torch.tensor(r[\"sub_tails\"], dtype=torch.float),   # L\n",
        "            \"obj_head\": torch.tensor(r[\"obj_heads\"], dtype=torch.float),   # R x L\n",
        "            \"obj_tail\": torch.tensor(r[\"obj_tails\"], dtype=torch.float)    # R x L\n",
        "        }\n",
        "\n",
        "def casrel_collate(batch):\n",
        "    # pad input_ids and attention_mask to max_len in batch; pad label matrices accordingly\n",
        "    max_len = max([b[\"input_ids\"].size(0) for b in batch])\n",
        "    R = num_rels\n",
        "    input_ids_p = []\n",
        "    attn_p = []\n",
        "    sub_head_p = []\n",
        "    sub_tail_p = []\n",
        "    obj_head_p = []\n",
        "    obj_tail_p = []\n",
        "    for b in batch:\n",
        "        l = b[\"input_ids\"].size(0)\n",
        "        pad_len = max_len - l\n",
        "        input_ids_p.append(torch.cat([b[\"input_ids\"], torch.full((pad_len,), tokenizer.pad_token_id, dtype=torch.long)]))\n",
        "        attn_p.append(torch.cat([b[\"attention_mask\"], torch.zeros(pad_len, dtype=torch.long)]))\n",
        "        # for token labels\n",
        "        sub_head_p.append(torch.cat([b[\"sub_head\"], torch.zeros(pad_len)]))\n",
        "        sub_tail_p.append(torch.cat([b[\"sub_tail\"], torch.zeros(pad_len)]))\n",
        "        # obj labels shape R x L -> pad each row\n",
        "        oh = b[\"obj_head\"]\n",
        "        ot = b[\"obj_tail\"]\n",
        "        # oh shape: R x L_cur\n",
        "        # pad to R x max_len\n",
        "        oh_p = torch.cat([oh, torch.zeros((R, pad_len))], dim=1)\n",
        "        ot_p = torch.cat([ot, torch.zeros((R, pad_len))], dim=1)\n",
        "        obj_head_p.append(oh_p)\n",
        "        obj_tail_p.append(ot_p)\n",
        "    batch_out = {\n",
        "        \"input_ids\": torch.stack(input_ids_p),\n",
        "        \"attention_mask\": torch.stack(attn_p),\n",
        "        \"sub_head\": torch.stack(sub_head_p),\n",
        "        \"sub_tail\": torch.stack(sub_tail_p),\n",
        "        \"obj_head\": torch.stack(obj_head_p),  # B x R x L\n",
        "        \"obj_tail\": torch.stack(obj_tail_p)\n",
        "    }\n",
        "    return batch_out\n",
        "\n",
        "# Create DataLoaders\n",
        "train_ds = CASRELDataset(train_records, tokenizer, max_len=MAX_LEN)\n",
        "dev_ds   = CASRELDataset(dev_records, tokenizer, max_len=MAX_LEN)\n",
        "test_ds  = CASRELDataset(test_records, tokenizer, max_len=MAX_LEN)\n",
        "\n",
        "# Optional: WeightedRandomSampler for records (here we keep it simple)\n",
        "# For CASREL we balance via pos_weights in BCE losses rather than sampler\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=casrel_collate)\n",
        "dev_loader   = DataLoader(dev_ds, batch_size=BATCH_SIZE, collate_fn=casrel_collate)\n",
        "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, collate_fn=casrel_collate)\n",
        "\n",
        "print(\"DataLoaders ready. Example batch sizes:\", BATCH_SIZE)\n",
        "\n",
        "# -------------------- CASREL-like Model (simplified & robust) --------------------\n",
        "class SimpleCasRel(nn.Module):\n",
        "    def __init__(self, bert_name, hidden_size=768, num_rels=0):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_name)\n",
        "        self.hidden_size = self.bert.config.hidden_size\n",
        "        self.num_rels = num_rels\n",
        "        # subject taggers (binary per token)\n",
        "        self.sub_head_proj = nn.Linear(self.hidden_size, 1)\n",
        "        self.sub_tail_proj = nn.Linear(self.hidden_size, 1)\n",
        "        # object taggers: conditioned on subject representation\n",
        "        # we will concat token repr and subject repr -> project to hidden -> predict R heads and R tails\n",
        "        self.obj_fc = nn.Linear(self.hidden_size*2, self.hidden_size)\n",
        "        self.obj_head_proj = nn.Linear(self.hidden_size, self.num_rels)\n",
        "        self.obj_tail_proj = nn.Linear(self.hidden_size, self.num_rels)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, subject_span=None):\n",
        "        # input: B x L\n",
        "        bert_out = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        seq_out = bert_out.last_hidden_state  # B x L x H\n",
        "        # subject logits\n",
        "        sub_head_logits = self.sub_head_proj(seq_out).squeeze(-1)  # B x L\n",
        "        sub_tail_logits = self.sub_tail_proj(seq_out).squeeze(-1)\n",
        "        # If subject_span is provided (B x 2: start,end) during inference, or B x list of gold during training:\n",
        "        # For training we will pass subject_span as a tensor B x 2 (the first subject occurrence) -- but many sentences have multiple subjects.\n",
        "        # To keep it practical: during training we compute object logits conditioned on *each gold subject* separately.\n",
        "        # Here, for a batch-level forward we support subject_span as:\n",
        "        # - None: return subject logits only\n",
        "        # - tensor of shape (B, 2): single subject per sample (start,end)\n",
        "        subj_cond_obj_head = None\n",
        "        subj_cond_obj_tail = None\n",
        "        if subject_span is not None:\n",
        "            # subject_span: B x 2 (start_idx, end_idx) - we compute subject representation as mean of token vectors in span\n",
        "            # subject_span can be tensor of ints\n",
        "            B, L, H = seq_out.size()\n",
        "            # build subj_repr: B x H\n",
        "            start = subject_span[:,0].clamp(0, L-1)\n",
        "            end = subject_span[:,1].clamp(0, L-1)\n",
        "            subj_repr = []\n",
        "            for i in range(B):\n",
        "                s = start[i].item(); e = end[i].item()\n",
        "                # average pooling of tokens s..e inclusive\n",
        "                if e < s:\n",
        "                    e = s\n",
        "                vec = seq_out[i, s:e+1, :].mean(dim=0)\n",
        "                subj_repr.append(vec)\n",
        "            subj_repr = torch.stack(subj_repr, dim=0)  # B x H\n",
        "            # expand subj repr to tokens and concat\n",
        "            subj_exp = subj_repr.unsqueeze(1).expand(-1, seq_out.size(1), -1)  # B x L x H\n",
        "            concat = torch.cat([seq_out, subj_exp], dim=-1)  # B x L x 2H\n",
        "            h = self.relu(self.obj_fc(concat))  # B x L x H\n",
        "            # project to R classes per token\n",
        "            # we want output shaped B x R x L -> transpose\n",
        "            oh = self.obj_head_proj(h)  # B x L x R\n",
        "            ot = self.obj_tail_proj(h)  # B x L x R\n",
        "            # transpose to B x R x L\n",
        "            subj_cond_obj_head = oh.permute(0,2,1)\n",
        "            subj_cond_obj_tail = ot.permute(0,2,1)\n",
        "        return sub_head_logits, sub_tail_logits, subj_cond_obj_head, subj_cond_obj_tail\n",
        "\n",
        "# instantiate\n",
        "model = SimpleCasRel(MODEL_NAME, num_rels=num_rels)\n",
        "model.to(DEVICE)\n",
        "\n",
        "# -------------------- Loss functions with pos-weights --------------------\n",
        "# subject BCE losses use scalar pos weight\n",
        "s_head_pos_weight = torch.tensor(weights[\"s_head\"], dtype=torch.float).to(DEVICE)\n",
        "s_tail_pos_weight = torch.tensor(weights[\"s_tail\"], dtype=torch.float).to(DEVICE)\n",
        "sub_head_loss_fn = nn.BCEWithLogitsLoss(pos_weight=s_head_pos_weight)\n",
        "sub_tail_loss_fn = nn.BCEWithLogitsLoss(pos_weight=s_tail_pos_weight)\n",
        "\n",
        "# object pos weights per relation -> create tensors of shape (R,) for pos_weight used per class\n",
        "obj_head_pos_weight = torch.tensor(weights[\"obj_head\"], dtype=torch.float).to(DEVICE) if num_rels>0 else torch.ones((1,), device=DEVICE)\n",
        "obj_tail_pos_weight = torch.tensor(weights[\"obj_tail\"], dtype=torch.float).to(DEVICE) if num_rels>0 else torch.ones((1,), device=DEVICE)\n",
        "# For BCEWithLogitsLoss with multi-label, we can pass pos_weight as (R,) by reshaping logits to (B*L, R).\n",
        "# We'll compute loss manually by flattening.\n",
        "\n",
        "# optimizer + scheduler\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=0.01)\n",
        "total_steps = len(train_loader) * EPOCHS if len(train_loader)>0 else 1\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=max(1,int(0.1*total_steps)), num_training_steps=total_steps)\n",
        "\n",
        "# -------------------- Utility: decode predicted triples from model outputs --------------------\n",
        "def decode_triples_from_preds(tokens, sub_head_logits, sub_tail_logits, obj_head_logits=None, obj_tail_logits=None, th_sub=0.5, th_obj=0.5):\n",
        "    # logits are raw (not sigmoid). We'll apply sigmoid thresholding.\n",
        "    # sub_head_logits, sub_tail_logits: L floats\n",
        "    # obj_head_logits, obj_tail_logits: R x L (optional) conditioned on a subject\n",
        "    import numpy as np\n",
        "    sub_h = (torch.sigmoid(sub_head_logits) > th_sub).cpu().numpy().astype(int)\n",
        "    sub_t = (torch.sigmoid(sub_tail_logits) > th_sub).cpu().numpy().astype(int)\n",
        "    L = len(sub_h)\n",
        "    subjects = []\n",
        "    # find all subject spans by pairing heads and tails naively: for each head index, find nearest tail >= head\n",
        "    for i in range(L):\n",
        "        if sub_h[i]==1:\n",
        "            # find tail j >= i where sub_t[j]==1; choose the first\n",
        "            j = None\n",
        "            for k in range(i, L):\n",
        "                if sub_t[k]==1:\n",
        "                    j = k\n",
        "                    break\n",
        "            if j is not None:\n",
        "                subjects.append((i,j))\n",
        "    triples = []\n",
        "    if obj_head_logits is None or obj_tail_logits is None:\n",
        "        return triples  # no objects predicted\n",
        "    # obj_head_logits: R x L tensor (for this subject)\n",
        "    oh_sig = torch.sigmoid(obj_head_logits).cpu().numpy()\n",
        "    ot_sig = torch.sigmoid(obj_tail_logits).cpu().numpy()\n",
        "    R, L = oh_sig.shape\n",
        "    for (s_start, s_end) in subjects:\n",
        "        for rid in range(R):\n",
        "            # find object heads where prob>th_obj\n",
        "            for i in range(L):\n",
        "                if oh_sig[rid, i] > th_obj:\n",
        "                    # find tail j >= i where ot_sig[rid,j] > th_obj\n",
        "                    j = None\n",
        "                    for k in range(i, L):\n",
        "                        if ot_sig[rid, k] > th_obj:\n",
        "                            j = k\n",
        "                            break\n",
        "                    if j is not None:\n",
        "                        triples.append({\n",
        "                            \"subject_span\": (s_start, s_end),\n",
        "                            \"object_span\": (i,j),\n",
        "                            \"predicate\": id2rel[rid]\n",
        "                        })\n",
        "    return triples\n",
        "\n",
        "# -------------------- Training loop (cascade-style)\n",
        "def train_and_evaluate(model, train_loader, dev_loader, test_loader, epochs=EPOCHS):\n",
        "    history = {\"train_loss\": [], \"dev_loss\":[]}\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        pbar = tqdm.tqdm(train_loader, desc=f\"Train Epoch {epoch}/{epochs}\")\n",
        "        for batch in pbar:\n",
        "            input_ids = batch[\"input_ids\"].to(DEVICE)            # B x L\n",
        "            attn = batch[\"attention_mask\"].to(DEVICE)\n",
        "            B, L = input_ids.shape\n",
        "            # sub labels: B x L\n",
        "            sub_head_gold = batch[\"sub_head\"].to(DEVICE)\n",
        "            sub_tail_gold = batch[\"sub_tail\"].to(DEVICE)\n",
        "            # obj labels: B x R x L\n",
        "            obj_head_gold = batch[\"obj_head\"].to(DEVICE)\n",
        "            obj_tail_gold = batch[\"obj_tail\"].to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            # forward -> sub logits\n",
        "            sub_head_logits, sub_tail_logits, _, _ = model(input_ids=input_ids, attention_mask=attn, subject_span=None)\n",
        "            # sub losses\n",
        "            loss_sh = sub_head_loss_fn(sub_head_logits, sub_head_gold)\n",
        "            loss_st = sub_tail_loss_fn(sub_tail_logits, sub_tail_gold)\n",
        "            # For object losses: for each sample, iterate over gold subject spans and compute object predictions conditioned on that subject\n",
        "            # To keep computation reasonable we will find all gold subject spans from sub_head_gold & sub_tail_gold and for each subject compute object logits\n",
        "            loss_obj_total = 0.0\n",
        "            obj_loss_count = 0\n",
        "            for i in range(B):\n",
        "                # find gold subject spans in sample i\n",
        "                sh = sub_head_gold[i].cpu().numpy().astype(int)\n",
        "                st = sub_tail_gold[i].cpu().numpy().astype(int)\n",
        "                subj_spans = []\n",
        "                for p in range(L):\n",
        "                    if sh[p]==1:\n",
        "                        # find tail\n",
        "                        q = None\n",
        "                        for k in range(p, L):\n",
        "                            if st[k]==1:\n",
        "                                q = k\n",
        "                                break\n",
        "                        if q is not None:\n",
        "                            subj_spans.append((p,q))\n",
        "                # if no gold subject spans, skip object loss for this sample\n",
        "                if len(subj_spans)==0:\n",
        "                    continue\n",
        "                for (s_start, s_end) in subj_spans:\n",
        "                    subj_span_tensor = torch.tensor([[s_start, s_end]], dtype=torch.long).to(DEVICE)  # 1 x 2\n",
        "                    # forward conditioned on this gold subject\n",
        "                    _, _, obj_head_logits, obj_tail_logits = model(input_ids=input_ids[i:i+1,:], attention_mask=attn[i:i+1,:], subject_span=subj_span_tensor)\n",
        "                    # obj logits: 1 x R x L\n",
        "                    # gold obj labels for this sample: R x L\n",
        "                    gold_oh = obj_head_gold[i]  # R x L\n",
        "                    gold_ot = obj_tail_gold[i]\n",
        "                    # Flatten to (R, L) -> compute BCEWithLogits per relation class using pos_weights\n",
        "                    # To match torch's pos_weight shape, we reshape logits to (R, L) -> (R,L) and apply BCE via flattening\n",
        "                    logits_oh = obj_head_logits.squeeze(0)  # R x L\n",
        "                    logits_ot = obj_tail_logits.squeeze(0)\n",
        "                    # compute BCEWithLogits per relation using pos weights vector\n",
        "                    # manual compute: BCEWithLogitsLoss with pos_weight for each class expects input shape (N,*) and pos_weight aligned with last dim\n",
        "                    # We'll compute loss relation-wise and average\n",
        "                    loss_rel_h = 0.0\n",
        "                    loss_rel_t = 0.0\n",
        "                    for rid in range(num_rels):\n",
        "                        # flatten over tokens\n",
        "                        logit_r_h = logits_oh[rid]       # L\n",
        "                        logit_r_t = logits_ot[rid]\n",
        "                        gold_r_h = gold_oh[rid].to(DEVICE)\n",
        "                        gold_r_t = gold_ot[rid].to(DEVICE)\n",
        "                        # create BCEWithLogits with pos_weight specific to this relation\n",
        "                        pos_w_h = torch.tensor(weights[\"obj_head\"][rid], dtype=torch.float).to(DEVICE)\n",
        "                        pos_w_t = torch.tensor(weights[\"obj_tail\"][rid], dtype=torch.float).to(DEVICE)\n",
        "                        loss_h = nn.BCEWithLogitsLoss(pos_weight=pos_w_h)(logit_r_h, gold_r_h)\n",
        "                        loss_t = nn.BCEWithLogitsLoss(pos_weight=pos_w_t)(logit_r_t, gold_r_t)\n",
        "                        loss_rel_h += loss_h\n",
        "                        loss_rel_t += loss_t\n",
        "                    loss_rel = (loss_rel_h + loss_rel_t) / max(1, num_rels)\n",
        "                    loss_obj_total += loss_rel\n",
        "                    obj_loss_count += 1\n",
        "            if obj_loss_count>0:\n",
        "                loss_obj_total = loss_obj_total / obj_loss_count\n",
        "            else:\n",
        "                loss_obj_total = torch.tensor(0.0, device=DEVICE)\n",
        "            loss = loss_sh + loss_st + loss_obj_total\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            total_loss += loss.item()\n",
        "            pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
        "        avg_train_loss = total_loss / max(1, len(train_loader))\n",
        "        history[\"train_loss\"].append(avg_train_loss)\n",
        "        # Validation loss + metrics\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        preds_triples = []\n",
        "        gold_triples = []\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm.tqdm(dev_loader, desc=\"Dev Eval\"):\n",
        "                input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "                attn = batch[\"attention_mask\"].to(DEVICE)\n",
        "                B,L = input_ids.shape\n",
        "                sub_head_gold = batch[\"sub_head\"].to(DEVICE)\n",
        "                sub_tail_gold = batch[\"sub_tail\"].to(DEVICE)\n",
        "                obj_head_gold = batch[\"obj_head\"].to(DEVICE)\n",
        "                obj_tail_gold = batch[\"obj_tail\"].to(DEVICE)\n",
        "                # subject predictions\n",
        "                sub_head_logits, sub_tail_logits, _, _ = model(input_ids=input_ids, attention_mask=attn, subject_span=None)\n",
        "                # loss on subject\n",
        "                loss_sh = sub_head_loss_fn(sub_head_logits, sub_head_gold)\n",
        "                loss_st = sub_tail_loss_fn(sub_tail_logits, sub_tail_gold)\n",
        "                # compute object loss using gold subjects (same as training)\n",
        "                loss_obj_total = 0.0; obj_loss_count=0\n",
        "                for i in range(B):\n",
        "                    sh = sub_head_gold[i].cpu().numpy().astype(int)\n",
        "                    st = sub_tail_gold[i].cpu().numpy().astype(int)\n",
        "                    subj_spans=[]\n",
        "                    for p in range(L):\n",
        "                        if sh[p]==1:\n",
        "                            q=None\n",
        "                            for k in range(p,L):\n",
        "                                if st[k]==1:\n",
        "                                    q=k; break\n",
        "                            if q is not None:\n",
        "                                subj_spans.append((p,q))\n",
        "                    if len(subj_spans)==0:\n",
        "                        continue\n",
        "                    for (s_start, s_end) in subj_spans:\n",
        "                        subj_span_tensor = torch.tensor([[s_start, s_end]], dtype=torch.long).to(DEVICE)\n",
        "                        _, _, obj_head_logits, obj_tail_logits = model(input_ids=input_ids[i:i+1,:], attention_mask=attn[i:i+1,:], subject_span=subj_span_tensor)\n",
        "                        logits_oh = obj_head_logits.squeeze(0)\n",
        "                        logits_ot = obj_tail_logits.squeeze(0)\n",
        "                        gold_oh = obj_head_gold[i]\n",
        "                        gold_ot = obj_tail_gold[i]\n",
        "                        loss_rel_h=0.0; loss_rel_t=0.0\n",
        "                        for rid in range(num_rels):\n",
        "                            pos_w_h = torch.tensor(weights[\"obj_head\"][rid], dtype=torch.float).to(DEVICE)\n",
        "                            pos_w_t = torch.tensor(weights[\"obj_tail\"][rid], dtype=torch.float).to(DEVICE)\n",
        "                            loss_rel_h += nn.BCEWithLogitsLoss(pos_weight=pos_w_h)(logits_oh[rid], gold_oh[rid].to(DEVICE))\n",
        "                            loss_rel_t += nn.BCEWithLogitsLoss(pos_weight=pos_w_t)(logits_ot[rid], gold_ot[rid].to(DEVICE))\n",
        "                        loss_obj_total += (loss_rel_h + loss_rel_t)/max(1,num_rels)\n",
        "                        obj_loss_count += 1\n",
        "                if obj_loss_count>0:\n",
        "                    loss_obj_total = loss_obj_total / obj_loss_count\n",
        "                else:\n",
        "                    loss_obj_total = torch.tensor(0.0, device=DEVICE)\n",
        "                batch_loss = loss_sh + loss_st + loss_obj_total\n",
        "                val_loss += batch_loss.item()\n",
        "                # decode predictions for metrics:\n",
        "                # get predictions per sample: subject spans from predicted sub logits, then for each subject predict objects\n",
        "                for i in range(B):\n",
        "                    # tokens are not passed, but we only need spans for metric: predicted subj/object spans + predicate\n",
        "                    sub_h_logits_i = sub_head_logits[i]   # L\n",
        "                    sub_t_logits_i = sub_tail_logits[i]\n",
        "                    # find subject spans\n",
        "                    sub_spans=[]\n",
        "                    sh_sig = (torch.sigmoid(sub_h_logits_i)>0.5).cpu().numpy().astype(int)\n",
        "                    st_sig = (torch.sigmoid(sub_t_logits_i)>0.5).cpu().numpy().astype(int)\n",
        "                    for p in range(L):\n",
        "                        if sh_sig[p]==1:\n",
        "                            q=None\n",
        "                            for k in range(p, L):\n",
        "                                if st_sig[k]==1:\n",
        "                                    q=k; break\n",
        "                            if q is not None:\n",
        "                                sub_spans.append((p,q))\n",
        "                    gold_for_sample = []\n",
        "                    # collect gold triples from gold label matrices\n",
        "                    # for each rid, find object spans where gold obj head/tail are 1\n",
        "                    gold_sub_spans = []\n",
        "                    shg = sub_head_gold[i].cpu().numpy().astype(int)\n",
        "                    stg = sub_tail_gold[i].cpu().numpy().astype(int)\n",
        "                    for p in range(L):\n",
        "                        if shg[p]==1:\n",
        "                            q=None\n",
        "                            for k in range(p,L):\n",
        "                                if stg[k]==1:\n",
        "                                    q=k; break\n",
        "                            if q is not None:\n",
        "                                gold_sub_spans.append((p,q))\n",
        "                    # for each gold subj, collect gold obj spans and add to gold_triples\n",
        "                    for (s_start, s_end) in gold_sub_spans:\n",
        "                        for rid in range(num_rels):\n",
        "                            ohg = obj_head_gold[i, rid].cpu().numpy().astype(int)\n",
        "                            otg = obj_tail_gold[i, rid].cpu().numpy().astype(int)\n",
        "                            for a in range(L):\n",
        "                                if ohg[a]==1:\n",
        "                                    b=None\n",
        "                                    for k in range(a,L):\n",
        "                                        if otg[k]==1:\n",
        "                                            b=k; break\n",
        "                                    if b is not None:\n",
        "                                        gold_for_sample.append(((s_start, s_end),(a,b), id2rel[rid]))\n",
        "                    gold_triples.extend(gold_for_sample)\n",
        "                    # predictions for objects: for each predicted subject span do forward conditioned on that subject\n",
        "                    pred_for_sample = []\n",
        "                    for (s_start, s_end) in sub_spans:\n",
        "                        subj_span_tensor = torch.tensor([[s_start, s_end]], dtype=torch.long).to(DEVICE)\n",
        "                        _, _, obj_head_logits, obj_tail_logits = model(input_ids=input_ids[i:i+1,:], attention_mask=attn[i:i+1,:], subject_span=subj_span_tensor)\n",
        "                        obj_head_logits = obj_head_logits.squeeze(0)  # R x L\n",
        "                        obj_tail_logits = obj_tail_logits.squeeze(0)\n",
        "                        # threshold\n",
        "                        oh_sig = (torch.sigmoid(obj_head_logits) > 0.5).cpu().numpy().astype(int)\n",
        "                        ot_sig = (torch.sigmoid(obj_tail_logits) > 0.5).cpu().numpy().astype(int)\n",
        "                        for rid in range(num_rels):\n",
        "                            for a in range(L):\n",
        "                                if oh_sig[rid,a]==1:\n",
        "                                    b=None\n",
        "                                    for k in range(a,L):\n",
        "                                        if ot_sig[rid,k]==1:\n",
        "                                            b=k; break\n",
        "                                    if b is not None:\n",
        "                                        pred_for_sample.append(((s_start, s_end),(a,b), id2rel[rid]))\n",
        "                    preds_triples.extend(pred_for_sample)\n",
        "        avg_val_loss = val_loss / max(1, len(dev_loader))\n",
        "        history[\"dev_loss\"].append(avg_val_loss)\n",
        "        # compute triple-level metrics (exact match of subject span, object span, predicate)\n",
        "        # convert gold_triples and preds_triples into sets of (s_s,s_e,o_s,o_e,pred)\n",
        "        def to_set(triples_list):\n",
        "            s = set()\n",
        "            for t in triples_list:\n",
        "                (ss,se),(os,oe),pred = t\n",
        "                s.add((ss,se,os,oe,pred))\n",
        "            return s\n",
        "        gold_set = to_set(gold_triples)\n",
        "        pred_set = to_set(preds_triples)\n",
        "        # calculate precision/recall/f1\n",
        "        tp = len(pred_set & gold_set)\n",
        "        fp = len(pred_set - gold_set)\n",
        "        fn = len(gold_set - pred_set)\n",
        "        prec = tp / (tp+fp) if tp+fp>0 else 0.0\n",
        "        rec = tp / (tp+fn) if tp+fn>0 else 0.0\n",
        "        f1 = 2*prec*rec/(prec+rec) if prec+rec>0 else 0.0\n",
        "        print(f\"\\nEpoch {epoch} -> train_loss: {avg_train_loss:.6f}  dev_loss: {avg_val_loss:.6f}  triples P/R/F: {prec:.4f}/{rec:.4f}/{f1:.4f}\")\n",
        "    return model, history\n",
        "\n",
        "# Run training + evaluation\n",
        "model, history = train_and_evaluate(model, train_loader, dev_loader, test_loader, epochs=EPOCHS)\n",
        "\n",
        "# Final evaluation on test set (same procedure as used for dev)\n",
        "def evaluate_final(model, data_loader):\n",
        "    model.eval()\n",
        "    preds_triples = []\n",
        "    gold_triples = []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm.tqdm(data_loader, desc=\"Final Eval\"):\n",
        "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "            attn = batch[\"attention_mask\"].to(DEVICE)\n",
        "            B,L = input_ids.shape\n",
        "            sub_head_gold = batch[\"sub_head\"].to(DEVICE)\n",
        "            sub_tail_gold = batch[\"sub_tail\"].to(DEVICE)\n",
        "            obj_head_gold = batch[\"obj_head\"].to(DEVICE)\n",
        "            obj_tail_gold = batch[\"obj_tail\"].to(DEVICE)\n",
        "            # predict subjects\n",
        "            sub_head_logits, sub_tail_logits, _, _ = model(input_ids=input_ids, attention_mask=attn, subject_span=None)\n",
        "            for i in range(B):\n",
        "                sh_sig = (torch.sigmoid(sub_head_logits[i])>0.5).cpu().numpy().astype(int)\n",
        "                st_sig = (torch.sigmoid(sub_tail_logits[i])>0.5).cpu().numpy().astype(int)\n",
        "                pred_subs=[]\n",
        "                gold_subs=[]\n",
        "                for p in range(L):\n",
        "                    if sh_sig[p]==1:\n",
        "                        q=None\n",
        "                        for k in range(p,L):\n",
        "                            if st_sig[k]==1:\n",
        "                                q=k; break\n",
        "                        if q is not None: pred_subs.append((p,q))\n",
        "                    # gold\n",
        "                shg = sub_head_gold[i].cpu().numpy().astype(int)\n",
        "                stg = sub_tail_gold[i].cpu().numpy().astype(int)\n",
        "                for p in range(L):\n",
        "                    if shg[p]==1:\n",
        "                        q=None\n",
        "                        for k in range(p,L):\n",
        "                            if stg[k]==1:\n",
        "                                q=k; break\n",
        "                        if q is not None: gold_subs.append((p,q))\n",
        "                # for each predicted subj, predict objects\n",
        "                for (s_start, s_end) in pred_subs:\n",
        "                    subj_span_tensor = torch.tensor([[s_start, s_end]], dtype=torch.long).to(DEVICE)\n",
        "                    _, _, obj_head_logits, obj_tail_logits = model(input_ids=input_ids[i:i+1,:], attention_mask=attn[i:i+1,:], subject_span=subj_span_tensor)\n",
        "                    oh_sig = (torch.sigmoid(obj_head_logits.squeeze(0))>0.5).cpu().numpy().astype(int)\n",
        "                    ot_sig = (torch.sigmoid(obj_tail_logits.squeeze(0))>0.5).cpu().numpy().astype(int)\n",
        "                    for rid in range(num_rels):\n",
        "                        for a in range(L):\n",
        "                            if oh_sig[rid,a]==1:\n",
        "                                b=None\n",
        "                                for k in range(a,L):\n",
        "                                    if ot_sig[rid,k]==1:\n",
        "                                        b=k; break\n",
        "                                if b is not None:\n",
        "                                    preds_triples.append(((s_start,s_end),(a,b), id2rel[rid]))\n",
        "                # gold triples from gold labels\n",
        "                for (s_start,s_end) in gold_subs:\n",
        "                    for rid in range(num_rels):\n",
        "                        ohg = obj_head_gold[i,rid].cpu().numpy().astype(int)\n",
        "                        otg = obj_tail_gold[i,rid].cpu().numpy().astype(int)\n",
        "                        for a in range(L):\n",
        "                            if ohg[a]==1:\n",
        "                                b=None\n",
        "                                for k in range(a,L):\n",
        "                                    if otg[k]==1:\n",
        "                                        b=k; break\n",
        "                                if b is not None:\n",
        "                                    gold_triples.append(((s_start,s_end),(a,b), id2rel[rid]))\n",
        "    # compute metrics\n",
        "    def to_set(triples_list):\n",
        "        s = set()\n",
        "        for t in triples_list:\n",
        "            (ss,se),(os,oe),pred = t\n",
        "            s.add((ss,se,os,oe,pred))\n",
        "        return s\n",
        "    gset = to_set(gold_triples)\n",
        "    pset = to_set(preds_triples)\n",
        "    tp = len(pset & gset)\n",
        "    fp = len(pset - gset)\n",
        "    fn = len(gset - pset)\n",
        "    prec = tp/(tp+fp) if tp+fp>0 else 0.0\n",
        "    rec = tp/(tp+fn) if tp+fn>0 else 0.0\n",
        "    f1 = 2*prec*rec/(prec+rec) if prec+rec>0 else 0.0\n",
        "    return {\"precision\":prec, \"recall\":rec, \"f1\":f1, \"tp\":tp, \"fp\":fp, \"fn\":fn}\n",
        "\n",
        "final_dev = evaluate_final(model, dev_loader)\n",
        "final_test = evaluate_final(model, test_loader)\n",
        "\n",
        "print(\"\\n=== CASREL FINAL ===\")\n",
        "print(\"DEV triple P/R/F: {:.4f} / {:.4f} / {:.4f}\".format(final_dev[\"precision\"], final_dev[\"recall\"], final_dev[\"f1\"]))\n",
        "print(\"TEST triple P/R/F: {:.4f} / {:.4f} / {:.4f}\".format(final_test[\"precision\"], final_test[\"recall\"], final_test[\"f1\"]))\n",
        "\n",
        "# Save outputs\n",
        "metrics = {\n",
        "    \"relation_list\": relation_list,\n",
        "    \"weights\": weights,\n",
        "    \"history\": history,\n",
        "    \"dev_final\": final_dev,\n",
        "    \"test_final\": final_test,\n",
        "    \"records_counts\": {\"train\": len(train_records), \"dev\": len(dev_records), \"test\": len(test_records)}\n",
        "}\n",
        "with open(OUTPUT_DIR / \"casrel_metrics_summary.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(metrics, f, indent=2)\n",
        "\n",
        "# save model + tokenizer\n",
        "model_to_save = model\n",
        "model_path = OUTPUT_DIR / \"model.pt\"\n",
        "torch.save(model_to_save.state_dict(), model_path)\n",
        "tokenizer.save_pretrained(str(OUTPUT_DIR))\n",
        "\n",
        "print(\"Saved CASREL model and metrics to:\", OUTPUT_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtdjjIXDPyKD",
        "outputId": "d0c24717-8fa1-48d0-b3a6-18513e50b124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Device: cuda\n",
            "Wrote 5700 records to /content/drive/MyDrive/Datasets_EE782_course_project/FinRED_dataset/casrel_train.jsonl\n",
            "Wrote 1007 records to /content/drive/MyDrive/Datasets_EE782_course_project/FinRED_dataset/casrel_dev.jsonl\n",
            "Wrote 1068 records to /content/drive/MyDrive/Datasets_EE782_course_project/FinRED_dataset/casrel_test.jsonl\n",
            "Number of predicates: 29\n",
            "Records: train 5582 dev 971 test 1034\n",
            "Computed pos-weights (approx): {'s_head': 37.49537774346583, 's_tail': 37.052623280754275, 'obj_head': [3603.7760656152827, 9288.230411991137, 1577.5620811924048, 1547.2051182871467, 2980.728358262613, 3658.393883963729, 992.909460934529, 4092.5592526684873, 4092.5592526684873, 5137.723294942058, 510.6949141722565, 1453.9397502774714, 475.370807740886, 224.50887000512708, 3658.393883963729, 1127.5981255719714, 1436.6190390677439, 5488.090784361573, 1653.246564018859, 3499.289804358119, 384.81469587090305, 552.944952860218, 508.5358639060425, 6036.999849075004, 1311.6086885238658, 185.6460585891452, 7789.96749064621, 5137.723294942058, 715.6765557398322], 'obj_tail': [3603.7760656152827, 9288.230411991137, 1577.5620811924048, 1547.2051182871467, 2980.728358262613, 3658.393883963729, 992.909460934529, 4092.5592526684873, 4092.5592526684873, 5137.723294942058, 508.5358639060425, 1453.9397502774714, 475.370807740886, 224.71962595820594, 3658.393883963729, 1127.5981255719714, 1436.6190390677439, 5488.090784361573, 1653.246564018859, 3499.289804358119, 384.19936142870915, 550.4155238574988, 507.46315682639334, 6036.999849075004, 1311.6086885238658, 184.92763650121043, 7789.96749064621, 5137.723294942058, 711.4483754824532]}\n",
            "DataLoaders ready. Example batch sizes: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 1/3: 100%|██████████| 698/698 [06:27<00:00,  1.80it/s, loss=1.7824]\n",
            "Dev Eval: 100%|██████████| 122/122 [01:05<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 -> train_loss: 2.117572  dev_loss: 1.061941  triples P/R/F: 0.0027/0.5860/0.0054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 2/3: 100%|██████████| 698/698 [06:27<00:00,  1.80it/s, loss=0.3985]\n",
            "Dev Eval: 100%|██████████| 122/122 [00:53<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2 -> train_loss: 0.774167  dev_loss: 0.918669  triples P/R/F: 0.0074/0.6210/0.0147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 3/3:   5%|▌         | 36/698 [00:20<05:41,  1.94it/s, loss=0.4153]"
          ]
        }
      ]
    }
  ]
}